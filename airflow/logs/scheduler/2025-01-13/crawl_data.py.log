[2025-01-13T02:09:43.019+0000] {processor.py:186} INFO - Started process (PID=69) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:09:43.024+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:09:43.043+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:09:43.042+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:09:48.988+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:09:49.132+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:09:49.129+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:09:50.944+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:09:50.943+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:09:52.846+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 9.870 seconds
[2025-01-13T02:10:23.253+0000] {processor.py:186} INFO - Started process (PID=75) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:10:23.290+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:10:23.295+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:10:23.294+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:10:23.866+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:10:23.904+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:10:23.904+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:10:23.950+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:10:23.949+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:10:24.006+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.761 seconds
[2025-01-13T02:10:54.443+0000] {processor.py:186} INFO - Started process (PID=82) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:10:54.458+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:10:54.460+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:10:54.460+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:10:54.893+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:10:54.912+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:10:54.912+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:10:54.930+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:10:54.930+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:10:55.009+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.571 seconds
[2025-01-13T02:11:25.239+0000] {processor.py:186} INFO - Started process (PID=89) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:11:25.241+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:11:25.243+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:11:25.243+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:11:25.679+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:11:25.700+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:11:25.699+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:11:25.721+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:11:25.721+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:11:25.779+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.546 seconds
[2025-01-13T02:11:56.216+0000] {processor.py:186} INFO - Started process (PID=96) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:11:56.264+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:11:56.269+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:11:56.269+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:11:58.571+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:11:58.641+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:11:58.641+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:11:58.692+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:11:58.691+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:12:22.152+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 26.031 seconds
[2025-01-13T02:12:53.017+0000] {processor.py:186} INFO - Started process (PID=109) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:12:53.018+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:12:53.026+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:12:53.025+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:12:54.032+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:12:54.238+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:12:54.237+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:12:54.307+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:12:54.307+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:12:57.444+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 4.663 seconds
[2025-01-13T02:13:14.575+0000] {processor.py:186} INFO - Started process (PID=94) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:13:14.622+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:13:14.688+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:13:14.687+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:13:22.049+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:13:22.247+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:13:22.247+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:13:22.360+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:13:22.360+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:13:22.840+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 8.289 seconds
[2025-01-13T02:13:28.335+0000] {processor.py:186} INFO - Started process (PID=116) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:13:28.339+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:13:28.345+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:13:28.344+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:13:31.013+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:13:31.063+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:13:31.062+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:13:31.168+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:13:31.168+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:13:44.479+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 16.152 seconds
[2025-01-13T02:13:53.348+0000] {processor.py:186} INFO - Started process (PID=103) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:13:53.372+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:13:53.374+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:13:53.374+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:14:00.258+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:14:00.737+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:14:00.736+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:14:00.778+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:14:00.778+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:14:01.694+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 8.353 seconds
[2025-01-13T02:14:14.885+0000] {processor.py:186} INFO - Started process (PID=129) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:14:14.886+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:14:14.890+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:14:14.889+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:14:20.277+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:14:20.404+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:14:20.404+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:14:20.650+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:14:20.650+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:14:21.520+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 6.693 seconds
[2025-01-13T02:14:31.867+0000] {processor.py:186} INFO - Started process (PID=112) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:14:31.868+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:14:31.870+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:14:31.870+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:14:34.314+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:14:34.361+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:14:34.360+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:14:34.409+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:14:34.408+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:14:34.455+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 2.644 seconds
[2025-01-13T02:14:52.002+0000] {processor.py:186} INFO - Started process (PID=136) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:14:52.012+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:14:52.028+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:14:52.027+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:14:55.810+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:14:56.344+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:14:56.343+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:14:56.611+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:14:56.610+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:15:01.408+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 9.453 seconds
[2025-01-13T02:15:05.902+0000] {processor.py:186} INFO - Started process (PID=120) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:15:05.960+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:15:05.962+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:15:05.962+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:15:12.692+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:15:13.161+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:15:13.161+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:15:13.528+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:15:13.528+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:15:18.130+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 12.252 seconds
[2025-01-13T02:15:50.676+0000] {processor.py:186} INFO - Started process (PID=127) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:15:50.932+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:15:51.142+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:15:51.107+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:15:52.373+0000] {processor.py:186} INFO - Started process (PID=149) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:15:52.377+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:15:52.631+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:15:52.631+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:16:02.065+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:16:04.160+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:16:04.159+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:16:05.021+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:16:05.020+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:16:05.310+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 13.686 seconds
[2025-01-13T02:16:22.172+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:16:22.171+0000] {timeout.py:68} ERROR - Process timed out, PID: 127
[2025-01-13T02:16:25.236+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:16:22.307+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/crawl_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/crawl_data.py", line 6, in <module>
    from bs4 import BeautifulSoup
  File "/home/airflow/.local/lib/python3.12/site-packages/bs4/__init__.py", line 37, in <module>
    from .builder import (
  File "/home/airflow/.local/lib/python3.12/site-packages/bs4/builder/__init__.py", line 9, in <module>
    from bs4.element import (
  File "/home/airflow/.local/lib/python3.12/site-packages/bs4/element.py", line 13, in <module>
    from bs4.formatter import (
  File "/home/airflow/.local/lib/python3.12/site-packages/bs4/formatter.py", line 1, in <module>
    from bs4.dammit import EntitySubstitution
  File "/home/airflow/.local/lib/python3.12/site-packages/bs4/dammit.py", line 67, in <module>
    class EntitySubstitution(object):
  File "/home/airflow/.local/lib/python3.12/site-packages/bs4/dammit.py", line 189, in EntitySubstitution
    CHARACTER_TO_HTML_ENTITY_RE) = _populate_class_variables()
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/bs4/dammit.py", line 187, in _populate_class_variables
    return unicode_to_name, name_to_unicode, re.compile(re_definition)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/re/__init__.py", line 228, in compile
    return _compile(pattern, flags)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/re/__init__.py", line 307, in _compile
    p = _compiler.compile(pattern, flags)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/re/_compiler.py", line 754, in compile
    code = _code(p, flags)
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/re/_compiler.py", line 584, in _code
    _compile_info(code, p, flags)
  File "/usr/local/lib/python3.12/re/_compiler.py", line 570, in _compile_info
    charset, hascased = _optimize_charset(charset)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/re/_compiler.py", line 288, in _optimize_charset
    continue
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/crawl_data.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.4/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.4/best-practices.html#reducing-dag-complexity, PID: 127
[2025-01-13T02:16:25.243+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:16:26.981+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 37.442 seconds
[2025-01-13T02:16:40.958+0000] {processor.py:186} INFO - Started process (PID=156) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:16:40.959+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:16:40.969+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:16:40.966+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:16:47.163+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:16:47.907+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:16:47.906+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:16:49.083+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:16:49.082+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:16:49.540+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 9.221 seconds
[2025-01-13T02:16:59.210+0000] {processor.py:186} INFO - Started process (PID=143) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:16:59.355+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:16:59.530+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:16:59.524+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:17:23.228+0000] {processor.py:186} INFO - Started process (PID=162) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:17:23.307+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:17:23.436+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:17:23.436+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:17:30.682+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:17:30.035+0000] {timeout.py:68} ERROR - Process timed out, PID: 143
[2025-01-13T02:17:31.370+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:17:30.697+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/crawl_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/crawl_data.py", line 7, in <module>
    from dotenv import load_dotenv
  File "/home/airflow/.local/lib/python3.12/site-packages/dotenv/__init__.py", line 3, in <module>
    from .main import (dotenv_values, find_dotenv, get_key, load_dotenv, set_key,
  File "/home/airflow/.local/lib/python3.12/site-packages/dotenv/main.py", line 14, in <module>
    from .variables import parse_variables
  File "/home/airflow/.local/lib/python3.12/site-packages/dotenv/variables.py", line 5, in <module>
    _posix_variable: Pattern[str] = re.compile(
                                    ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/re/__init__.py", line 228, in compile
    return _compile(pattern, flags)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/re/__init__.py", line 325, in _compile
    del _cache2[next(iter(_cache2))]
                     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/crawl_data.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.4/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.4/best-practices.html#reducing-dag-complexity, PID: 143
[2025-01-13T02:17:31.376+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:17:32.803+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 34.677 seconds
[2025-01-13T02:17:33.305+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:17:33.563+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:17:33.562+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:17:33.749+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:17:33.748+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:17:33.966+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 11.846 seconds
[2025-01-13T02:18:09.440+0000] {processor.py:186} INFO - Started process (PID=174) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:18:09.444+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:18:09.655+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:18:09.627+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:18:09.979+0000] {processor.py:186} INFO - Started process (PID=151) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:18:10.243+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:18:12.420+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:18:12.316+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:18:20.040+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:18:20.883+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:18:20.864+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:18:21.721+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:18:21.720+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:18:22.002+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 14.618 seconds
[2025-01-13T02:18:53.732+0000] {processor.py:186} INFO - Started process (PID=181) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:18:53.751+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:18:53.944+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:18:53.943+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:18:57.590+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:18:57.680+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:18:57.679+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:18:57.791+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:18:57.790+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:18:57.925+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 4.613 seconds
[2025-01-13T02:19:33.453+0000] {processor.py:186} INFO - Started process (PID=187) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:19:33.457+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:19:33.476+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:19:33.471+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:19:37.077+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:19:38.139+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:19:38.139+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:19:38.676+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:19:38.675+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:19:38.893+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 5.663 seconds
[2025-01-13T02:20:12.551+0000] {processor.py:186} INFO - Started process (PID=201) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:20:12.592+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:20:12.704+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:20:12.702+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:20:21.804+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:20:22.570+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:20:22.569+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:20:23.439+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:20:23.437+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:20:23.599+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 11.454 seconds
[2025-01-13T02:20:24.806+0000] {processor.py:186} INFO - Started process (PID=182) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:20:24.905+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:20:25.273+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:20:25.224+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:20:54.686+0000] {processor.py:186} INFO - Started process (PID=207) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:20:54.705+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:20:54.919+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:20:54.918+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:20:56.785+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:20:56.738+0000] {timeout.py:68} ERROR - Process timed out, PID: 182
[2025-01-13T02:20:57.432+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:20:56.791+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/crawl_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/crawl_data.py", line 8, in <module>
    import mysql.connector
  File "/home/airflow/.local/lib/python3.12/site-packages/mysql/connector/__init__.py", line 73, in <module>
    from .pooling import connect
  File "/home/airflow/.local/lib/python3.12/site-packages/mysql/connector/pooling.py", line 43, in <module>
    import dns.resolver
  File "/home/airflow/.local/lib/python3.12/site-packages/dns/resolver.py", line 30, in <module>
    import dns._ddr
  File "/home/airflow/.local/lib/python3.12/site-packages/dns/_ddr.py", line 12, in <module>
    import dns.nameserver
  File "/home/airflow/.local/lib/python3.12/site-packages/dns/nameserver.py", line 5, in <module>
    import dns.asyncquery
  File "/home/airflow/.local/lib/python3.12/site-packages/dns/asyncquery.py", line 40, in <module>
    from dns.query import (
  File "/home/airflow/.local/lib/python3.12/site-packages/dns/query.py", line 46, in <module>
    import dns.xfr
  File "/home/airflow/.local/lib/python3.12/site-packages/dns/xfr.py", line 29, in <module>
    import dns.zone
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1091, in get_code
  File "<frozen importlib._bootstrap_external>", line 1191, in get_data
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/crawl_data.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.4/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.4/best-practices.html#reducing-dag-complexity, PID: 182
[2025-01-13T02:20:57.690+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:20:57.875+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:20:57.967+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:20:57.966+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:20:58.223+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:20:58.223+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:20:58.391+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 4.180 seconds
[2025-01-13T02:20:58.782+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 34.533 seconds
[2025-01-13T02:21:32.772+0000] {processor.py:186} INFO - Started process (PID=214) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:21:32.811+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:21:32.832+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:21:32.831+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:21:59.158+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:22:01.927+0000] {processor.py:186} INFO - Started process (PID=191) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:22:02.190+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:22:02.189+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:22:03.963+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:22:03.951+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:22:05.026+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 33.604 seconds
[2025-01-13T02:22:04.174+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:22:12.463+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:22:12.458+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:22:37.018+0000] {processor.py:186} INFO - Started process (PID=227) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:22:37.019+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:22:37.039+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:22:37.038+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:22:39.800+0000] {processor.py:186} INFO - Started process (PID=199) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:22:39.848+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:22:40.300+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:22:40.299+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:22:43.978+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:22:53.947+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:22:53.946+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:22:54.754+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:22:54.753+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:22:56.512+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 20.684 seconds
[2025-01-13T02:23:26.711+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:23:26.710+0000] {timeout.py:68} ERROR - Process timed out, PID: 199
[2025-01-13T02:23:37.894+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:23:26.752+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/crawl_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/crawl_data.py", line 5, in <module>
    import cloudscraper
  File "/home/airflow/.local/lib/python3.12/site-packages/cloudscraper/__init__.py", line 31, in <module>
    from .exceptions import (
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1128, in get_code
  File "<frozen importlib._bootstrap_external>", line 757, in _compile_bytecode
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/crawl_data.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.4/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.4/best-practices.html#reducing-dag-complexity, PID: 199
[2025-01-13T02:23:37.902+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:23:41.261+0000] {processor.py:186} INFO - Started process (PID=235) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:23:41.264+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:23:41.329+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:23:41.327+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:24:00.850+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:24:04.246+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:24:04.245+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:24:07.360+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:24:07.360+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:24:08.127+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 30.345 seconds
[2025-01-13T02:24:39.946+0000] {processor.py:186} INFO - Started process (PID=246) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:24:40.011+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:24:40.317+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:24:40.292+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:24:56.474+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:24:59.847+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:24:59.845+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:25:00.549+0000] {processor.py:186} INFO - Started process (PID=215) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:25:02.100+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:25:02.100+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:25:02.467+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 23.438 seconds
[2025-01-13T02:25:01.248+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:25:03.665+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:25:03.662+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:25:29.167+0000] {processor.py:186} INFO - Started process (PID=223) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:25:29.424+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:25:31.153+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:25:30.444+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:25:34.749+0000] {processor.py:186} INFO - Started process (PID=254) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:25:34.824+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:25:35.023+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:25:35.020+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:25:38.221+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:25:38.484+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:25:38.483+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:25:38.604+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:25:38.604+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:25:38.697+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 4.221 seconds
[2025-01-13T02:26:07.774+0000] {processor.py:186} INFO - Started process (PID=233) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:26:07.911+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:26:08.154+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:26:08.145+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:26:15.091+0000] {processor.py:186} INFO - Started process (PID=261) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:26:15.097+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:26:15.824+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:26:15.823+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:26:24.455+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:26:24.823+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:26:24.822+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:26:25.173+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:26:25.172+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:26:25.383+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 11.219 seconds
[2025-01-13T02:26:42.220+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:26:42.216+0000] {timeout.py:68} ERROR - Process timed out, PID: 233
[2025-01-13T02:26:42.426+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:26:42.318+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/crawl_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/crawl_data.py", line 30, in <module>
    scraper = cloudscraper.create_scraper(browser='chrome')
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/cloudscraper/__init__.py", line 319, in create_scraper
    scraper = cls(**kwargs)
              ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/cloudscraper/__init__.py", line 168, in __init__
    CipherSuiteAdapter(
  File "/home/airflow/.local/lib/python3.12/site-packages/cloudscraper/__init__.py", line 75, in __init__
    self.ssl_context = ssl.create_default_context(ssl.Purpose.SERVER_AUTH)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/ssl.py", line 712, in create_default_context
    context.load_default_certs(purpose)
  File "/usr/local/lib/python3.12/ssl.py", line 534, in load_default_certs
    self.set_default_verify_paths()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/crawl_data.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.4/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.4/best-practices.html#reducing-dag-complexity, PID: 233
[2025-01-13T02:26:42.516+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:27:01.765+0000] {processor.py:186} INFO - Started process (PID=275) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:27:01.812+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:27:01.876+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:27:01.875+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:27:05.042+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:27:05.238+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:27:05.237+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:27:05.378+0000] {processor.py:186} INFO - Started process (PID=250) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:27:05.488+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:27:05.488+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:27:05.524+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:27:05.653+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 7.660 seconds
[2025-01-13T02:27:05.664+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:27:05.664+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:27:19.885+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:27:20.755+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:27:20.752+0000] {taskinstance.py:3313} ERROR - {'DAG Id': 'topcv_scraper', 'Task Id': 'scrape_urls', 'Run Id': 'scheduled__2025-01-11T00:00:00+00:00', 'Hostname': '91a339479d94', 'External Executor Id': '44948f31-508f-4439-8d6b-cc6afd825d0e'}
[2025-01-13T02:27:23.664+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:27:23.663+0000] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=topcv_scraper, task_id=scrape_urls, run_id=scheduled__2025-01-11T00:00:00+00:00, execution_date=20250111T000000, start_date=20250113T021604, end_date=20250113T022721
[2025-01-13T02:27:24.336+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:27:24.336+0000] {processor.py:876} INFO - Executed callback for <TaskInstance: topcv_scraper.scrape_urls scheduled__2025-01-11T00:00:00+00:00 [failed]> in state failed
[2025-01-13T02:27:24.446+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:27:24.446+0000] {taskinstance.py:3313} ERROR - {'DAG Id': 'topcv_scraper', 'Task Id': 'scrape_urls', 'Run Id': 'scheduled__2025-01-11T00:00:00+00:00', 'Hostname': '91a339479d94', 'External Executor Id': '44948f31-508f-4439-8d6b-cc6afd825d0e'}
[2025-01-13T02:27:24.582+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:27:24.582+0000] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=topcv_scraper, task_id=scrape_urls, run_id=scheduled__2025-01-11T00:00:00+00:00, execution_date=20250111T000000, start_date=20250113T021604, end_date=20250113T022724
[2025-01-13T02:27:24.718+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:27:24.717+0000] {processor.py:876} INFO - Executed callback for <TaskInstance: topcv_scraper.scrape_urls scheduled__2025-01-11T00:00:00+00:00 [failed]> in state failed
[2025-01-13T02:27:24.778+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:27:24.778+0000] {taskinstance.py:3313} ERROR - {'DAG Id': 'topcv_scraper', 'Task Id': 'scrape_urls', 'Run Id': 'scheduled__2025-01-11T00:00:00+00:00', 'Hostname': '91a339479d94', 'External Executor Id': '44948f31-508f-4439-8d6b-cc6afd825d0e'}
[2025-01-13T02:27:24.945+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:27:24.945+0000] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=topcv_scraper, task_id=scrape_urls, run_id=scheduled__2025-01-11T00:00:00+00:00, execution_date=20250111T000000, start_date=20250113T021604, end_date=20250113T022724
[2025-01-13T02:27:25.043+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:27:25.042+0000] {processor.py:876} INFO - Executed callback for <TaskInstance: topcv_scraper.scrape_urls scheduled__2025-01-11T00:00:00+00:00 [failed]> in state failed
[2025-01-13T02:27:25.076+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:27:25.075+0000] {taskinstance.py:3313} ERROR - {'DAG Id': 'topcv_scraper', 'Task Id': 'scrape_urls', 'Run Id': 'scheduled__2025-01-11T00:00:00+00:00', 'Hostname': '91a339479d94', 'External Executor Id': '44948f31-508f-4439-8d6b-cc6afd825d0e'}
[2025-01-13T02:27:25.156+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:27:25.156+0000] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=topcv_scraper, task_id=scrape_urls, run_id=scheduled__2025-01-11T00:00:00+00:00, execution_date=20250111T000000, start_date=20250113T021604, end_date=20250113T022725
[2025-01-13T02:27:25.179+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:27:25.179+0000] {processor.py:876} INFO - Executed callback for <TaskInstance: topcv_scraper.scrape_urls scheduled__2025-01-11T00:00:00+00:00 [failed]> in state failed
[2025-01-13T02:27:36.558+0000] {processor.py:186} INFO - Started process (PID=282) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:27:36.569+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:27:36.572+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:27:36.572+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:27:43.194+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:27:43.580+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:27:43.580+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:27:43.685+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:27:43.685+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:27:43.771+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 7.221 seconds
[2025-01-13T02:27:44.849+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:27:44.817+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:27:46.153+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:27:46.152+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:27:46.529+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 42.438 seconds
[2025-01-13T02:28:14.287+0000] {processor.py:186} INFO - Started process (PID=289) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:28:14.290+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:28:14.298+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:28:14.296+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:28:15.050+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:28:15.088+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:28:15.087+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:28:15.141+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:28:15.140+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:28:17.609+0000] {processor.py:186} INFO - Started process (PID=265) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:28:17.610+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:28:17.678+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:28:17.676+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:28:18.491+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:28:18.577+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:28:18.575+0000] {taskinstance.py:3313} ERROR - {'DAG Id': 'topcv_scraper', 'Task Id': 'scrape_urls', 'Run Id': 'scheduled__2025-01-11T00:00:00+00:00', 'Hostname': '91a339479d94', 'External Executor Id': '44948f31-508f-4439-8d6b-cc6afd825d0e'}
[2025-01-13T02:28:18.652+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:28:18.652+0000] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=topcv_scraper, task_id=scrape_urls, run_id=scheduled__2025-01-11T00:00:00+00:00, execution_date=20250111T000000, start_date=20250113T021604, end_date=20250113T022818
[2025-01-13T02:28:25.538+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:28:25.538+0000] {processor.py:876} INFO - Executed callback for <TaskInstance: topcv_scraper.scrape_urls scheduled__2025-01-11T00:00:00+00:00 [failed]> in state failed
[2025-01-13T02:28:25.573+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 11.294 seconds
[2025-01-13T02:28:25.720+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:28:25.719+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:28:25.821+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:28:25.820+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:28:25.982+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 8.570 seconds
[2025-01-13T02:29:00.030+0000] {processor.py:186} INFO - Started process (PID=302) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:29:00.031+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:29:00.037+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:29:00.035+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:29:00.040+0000] {processor.py:186} INFO - Started process (PID=274) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:29:00.044+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:29:00.057+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:29:00.056+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:29:01.735+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:29:01.934+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:29:01.933+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:29:02.058+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:29:02.058+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:29:02.214+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 2.212 seconds
[2025-01-13T02:29:02.820+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:29:03.002+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:29:02.990+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:29:03.298+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:29:03.296+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:29:03.513+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 3.511 seconds
[2025-01-13T02:29:33.271+0000] {processor.py:186} INFO - Started process (PID=309) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:29:33.287+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:29:33.306+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:29:33.303+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:29:33.987+0000] {processor.py:186} INFO - Started process (PID=284) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:29:33.992+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:29:34.012+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:29:34.010+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:29:35.963+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:29:36.240+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:29:36.216+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:29:36.571+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:29:36.568+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:29:36.735+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 3.521 seconds
[2025-01-13T02:29:37.337+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:29:37.421+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:29:37.421+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:29:37.617+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:29:37.617+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:29:37.756+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 3.908 seconds
[2025-01-13T02:30:07.295+0000] {processor.py:186} INFO - Started process (PID=315) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:30:07.303+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:30:07.323+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:30:07.322+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:30:09.036+0000] {processor.py:186} INFO - Started process (PID=292) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:30:09.235+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:30:09.266+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:30:09.265+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:30:09.540+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:30:09.743+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:30:09.742+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:30:09.970+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:30:09.967+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:30:10.078+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 2.842 seconds
[2025-01-13T02:30:12.658+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:30:13.186+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:30:13.185+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:30:13.792+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:30:13.791+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:30:14.014+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 5.133 seconds
[2025-01-13T02:30:44.448+0000] {processor.py:186} INFO - Started process (PID=321) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:30:44.483+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:30:44.730+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:30:44.728+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:30:45.967+0000] {processor.py:186} INFO - Started process (PID=300) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:30:46.101+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:30:46.281+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:30:46.280+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:30:49.893+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:30:50.278+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:30:50.274+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:30:50.744+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:30:50.742+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:30:51.053+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 6.946 seconds
[2025-01-13T02:30:52.806+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:30:53.261+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:30:53.259+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:30:53.608+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:30:53.607+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:30:54.143+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 9.276 seconds
[2025-01-13T02:31:21.365+0000] {processor.py:186} INFO - Started process (PID=328) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:31:21.395+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:31:21.398+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:31:21.398+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:31:23.536+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:31:23.783+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:31:23.780+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:31:23.856+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:31:23.855+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:31:23.981+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 2.665 seconds
[2025-01-13T02:31:24.669+0000] {processor.py:186} INFO - Started process (PID=309) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:31:24.712+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:31:24.715+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:31:24.714+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:31:27.026+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:31:27.412+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:31:27.411+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:31:27.649+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:31:27.649+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:31:27.754+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 3.097 seconds
[2025-01-13T02:31:54.187+0000] {processor.py:186} INFO - Started process (PID=341) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:31:54.193+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:31:54.211+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:31:54.210+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:31:56.121+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:31:56.201+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:31:56.201+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:31:56.573+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:31:56.572+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:31:56.618+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 2.471 seconds
[2025-01-13T02:31:58.820+0000] {processor.py:186} INFO - Started process (PID=317) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:31:58.871+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:31:58.911+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:31:58.910+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:32:23.139+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:32:25.843+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:32:25.835+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:32:26.452+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:32:26.446+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:32:26.937+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 28.349 seconds
[2025-01-13T02:32:29.117+0000] {processor.py:186} INFO - Started process (PID=347) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:32:29.130+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:32:29.164+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:32:29.162+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:32:34.006+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:32:34.565+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:32:34.565+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:32:34.956+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:32:34.956+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:32:35.149+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 6.384 seconds
[2025-01-13T02:32:59.158+0000] {processor.py:186} INFO - Started process (PID=327) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:32:59.161+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:32:59.173+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:32:59.172+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:33:00.359+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:33:00.443+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:33:00.440+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:33:00.519+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:33:00.518+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:33:00.581+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 1.460 seconds
[2025-01-13T02:33:05.287+0000] {processor.py:186} INFO - Started process (PID=354) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:33:05.293+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:33:05.303+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:33:05.301+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:33:06.318+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:33:06.429+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:33:06.428+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:33:06.519+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:33:06.519+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:33:06.634+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 1.361 seconds
[2025-01-13T02:33:31.383+0000] {processor.py:186} INFO - Started process (PID=335) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:33:31.386+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:33:31.396+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:33:31.396+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:33:32.157+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:33:32.201+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:33:32.201+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:33:32.247+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:33:32.247+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:33:32.326+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.987 seconds
[2025-01-13T02:33:36.904+0000] {processor.py:186} INFO - Started process (PID=362) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:33:36.908+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:33:36.912+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:33:36.911+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:33:37.492+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:33:37.568+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:33:37.567+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:33:37.663+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:33:37.663+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:33:37.929+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 1.048 seconds
[2025-01-13T02:34:02.966+0000] {processor.py:186} INFO - Started process (PID=343) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:34:02.970+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:34:02.973+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:34:02.973+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:34:03.904+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:34:04.138+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:34:04.138+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:34:04.249+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:34:04.248+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:34:04.431+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 1.475 seconds
[2025-01-13T02:34:08.998+0000] {processor.py:186} INFO - Started process (PID=369) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:34:09.007+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:34:09.013+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:34:09.013+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:34:09.812+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:34:09.850+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:34:09.849+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:34:09.875+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:34:09.875+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:34:09.925+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.937 seconds
[2025-01-13T02:34:37.584+0000] {processor.py:186} INFO - Started process (PID=345) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:34:37.598+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:34:37.715+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:34:37.709+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:34:41.362+0000] {processor.py:186} INFO - Started process (PID=376) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:34:41.381+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:34:41.562+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:34:41.559+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:34:45.430+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:34:45.751+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:34:45.749+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:34:45.921+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:34:46.132+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:34:46.132+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:34:46.253+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:34:46.248+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:34:46.278+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 5.424 seconds
[2025-01-13T02:34:46.435+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:34:46.435+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:34:46.483+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 9.422 seconds
[2025-01-13T02:35:16.983+0000] {processor.py:186} INFO - Started process (PID=354) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:35:17.180+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:35:17.314+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:35:17.309+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:35:17.315+0000] {processor.py:186} INFO - Started process (PID=383) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:35:17.319+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:35:17.362+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:35:17.361+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:35:20.289+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:35:20.326+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:35:20.325+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:35:20.362+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:35:20.362+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:35:20.396+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 3.594 seconds
[2025-01-13T02:35:20.520+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:35:20.560+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:35:20.559+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:35:20.602+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:35:20.601+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:35:20.639+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 3.858 seconds
[2025-01-13T02:35:50.643+0000] {processor.py:186} INFO - Started process (PID=390) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:35:50.690+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:35:50.698+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:35:50.694+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:35:51.161+0000] {processor.py:186} INFO - Started process (PID=363) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:35:51.164+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:35:51.188+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:35:51.187+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:35:52.063+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:35:52.265+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:35:52.264+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:35:52.331+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:35:52.331+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:35:52.501+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 1.865 seconds
[2025-01-13T02:35:53.008+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:35:53.082+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:35:53.081+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:35:53.146+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:35:53.146+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:35:53.326+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 2.188 seconds
[2025-01-13T02:36:23.137+0000] {processor.py:186} INFO - Started process (PID=397) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:36:23.226+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:36:23.236+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:36:23.235+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:36:24.035+0000] {processor.py:186} INFO - Started process (PID=372) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:36:24.057+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:36:24.065+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:36:24.064+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:36:24.423+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:36:24.520+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:36:24.519+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:36:24.571+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:36:24.574+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:36:24.574+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:36:24.609+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:36:24.608+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:36:24.642+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 1.533 seconds
[2025-01-13T02:36:24.655+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:36:24.655+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:36:24.744+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.728 seconds
[2025-01-13T02:36:55.572+0000] {processor.py:186} INFO - Started process (PID=404) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:36:55.577+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:36:55.631+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:36:55.627+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:36:55.738+0000] {processor.py:186} INFO - Started process (PID=381) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:36:55.744+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:36:55.780+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:36:55.776+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:36:57.763+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:36:57.882+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:36:57.881+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:36:57.995+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:36:57.995+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:36:58.009+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:36:58.102+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 2.885 seconds
[2025-01-13T02:36:58.141+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:36:58.140+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:36:58.188+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:36:58.188+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:36:58.222+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 2.589 seconds
[2025-01-13T02:37:36.031+0000] {processor.py:186} INFO - Started process (PID=390) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:37:36.107+0000] {processor.py:186} INFO - Started process (PID=411) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:37:37.011+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:37:37.005+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:37:38.875+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:37:38.871+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:37:38.908+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:37:38.872+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:37:55.393+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:37:55.433+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:37:55.658+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:37:55.658+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:37:55.748+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:37:55.748+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:37:55.846+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:37:55.846+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:37:55.989+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 21.185 seconds
[2025-01-13T02:37:56.061+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:37:56.061+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:37:56.221+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 21.212 seconds
[2025-01-13T02:38:26.695+0000] {processor.py:186} INFO - Started process (PID=425) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:38:26.757+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:38:26.901+0000] {processor.py:186} INFO - Started process (PID=399) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:38:26.913+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:38:26.907+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:38:26.918+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:38:26.975+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:38:26.972+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:38:31.187+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:38:31.869+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:38:31.868+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:38:32.079+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:38:32.079+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:38:32.258+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 5.610 seconds
[2025-01-13T02:38:32.346+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:38:32.487+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:38:32.480+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:38:32.710+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:38:32.709+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:38:32.863+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 6.186 seconds
[2025-01-13T02:39:02.528+0000] {processor.py:186} INFO - Started process (PID=432) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:39:02.530+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:39:02.546+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:39:02.545+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:39:03.155+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:39:03.218+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:39:03.217+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:39:03.284+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:39:03.281+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:39:03.312+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.793 seconds
[2025-01-13T02:39:03.892+0000] {processor.py:186} INFO - Started process (PID=408) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:39:03.894+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:39:03.899+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:39:03.899+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:39:04.765+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:39:04.814+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:39:04.813+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:39:04.902+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:39:04.895+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:39:04.979+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 1.097 seconds
[2025-01-13T02:39:33.817+0000] {processor.py:186} INFO - Started process (PID=439) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:39:33.821+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:39:33.834+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:39:33.832+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:39:34.677+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:39:34.754+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:39:34.753+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:39:34.799+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:39:34.798+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:39:34.842+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 1.057 seconds
[2025-01-13T02:39:35.306+0000] {processor.py:186} INFO - Started process (PID=417) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:39:35.307+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:39:35.311+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:39:35.311+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:39:35.743+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:39:35.788+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:39:35.788+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:39:35.817+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:39:35.817+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:39:35.848+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.561 seconds
[2025-01-13T02:40:05.124+0000] {processor.py:186} INFO - Started process (PID=446) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:40:05.127+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:40:05.136+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:40:05.135+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:40:05.632+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:40:05.666+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:40:05.665+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:40:05.696+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:40:05.696+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:40:05.723+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.621 seconds
[2025-01-13T02:40:06.215+0000] {processor.py:186} INFO - Started process (PID=426) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:40:06.218+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:40:06.228+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:40:06.227+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:40:06.629+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:40:06.673+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:40:06.673+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:40:06.718+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:40:06.717+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:40:06.743+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.552 seconds
[2025-01-13T02:40:35.924+0000] {processor.py:186} INFO - Started process (PID=453) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:40:35.925+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:40:35.927+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:40:35.927+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:40:36.265+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:40:36.293+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:40:36.293+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:40:36.322+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:40:36.322+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:40:36.345+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.427 seconds
[2025-01-13T02:40:36.791+0000] {processor.py:186} INFO - Started process (PID=435) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:40:36.792+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:40:36.795+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:40:36.794+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:40:37.163+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:40:37.192+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:40:37.191+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:40:37.219+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:40:37.219+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:40:37.242+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.459 seconds
[2025-01-13T02:41:06.504+0000] {processor.py:186} INFO - Started process (PID=460) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:41:06.505+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:41:06.508+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:41:06.507+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:41:06.844+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:41:06.867+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:41:06.867+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:41:06.893+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:41:06.893+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:41:06.913+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.416 seconds
[2025-01-13T02:41:07.454+0000] {processor.py:186} INFO - Started process (PID=443) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:41:07.455+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:41:07.457+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:41:07.457+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:41:07.869+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:41:07.905+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:41:07.904+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:41:07.938+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:41:07.938+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:41:07.963+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.515 seconds
[2025-01-13T02:41:37.179+0000] {processor.py:186} INFO - Started process (PID=468) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:41:37.180+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:41:37.182+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:41:37.182+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:41:37.503+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:41:37.542+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:41:37.541+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:41:37.572+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:41:37.572+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:41:37.594+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.421 seconds
[2025-01-13T02:41:38.206+0000] {processor.py:186} INFO - Started process (PID=451) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:41:38.207+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:41:38.209+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:41:38.209+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:41:38.521+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:41:38.550+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:41:38.549+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:41:38.576+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:41:38.575+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:41:38.595+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.395 seconds
[2025-01-13T02:42:07.858+0000] {processor.py:186} INFO - Started process (PID=475) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:42:07.859+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:42:07.861+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:42:07.861+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:42:08.367+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:42:08.419+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:42:08.418+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:42:08.466+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:42:08.466+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:42:08.497+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.645 seconds
[2025-01-13T02:42:08.886+0000] {processor.py:186} INFO - Started process (PID=460) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:42:08.887+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:42:08.891+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:42:08.890+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:42:09.254+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:42:09.281+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:42:09.280+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:42:09.308+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:42:09.307+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:42:09.328+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.451 seconds
[2025-01-13T02:42:38.622+0000] {processor.py:186} INFO - Started process (PID=483) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:42:38.623+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:42:38.626+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:42:38.626+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:42:38.945+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:42:38.969+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:42:38.968+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:42:38.996+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:42:38.996+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:42:39.028+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.413 seconds
[2025-01-13T02:42:39.579+0000] {processor.py:186} INFO - Started process (PID=468) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:42:39.580+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:42:39.582+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:42:39.582+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:42:39.991+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:42:40.019+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:42:40.018+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:42:40.051+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:42:40.051+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:42:40.079+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.507 seconds
[2025-01-13T02:43:09.262+0000] {processor.py:186} INFO - Started process (PID=490) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:43:09.264+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:43:09.270+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:43:09.269+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:43:09.847+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:43:09.880+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:43:09.879+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:43:09.931+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:43:09.930+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:43:09.968+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.716 seconds
[2025-01-13T02:43:10.365+0000] {processor.py:186} INFO - Started process (PID=470) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:43:10.367+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:43:10.371+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:43:10.371+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:43:10.904+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:43:10.934+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:43:10.933+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:43:10.964+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:43:10.964+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:43:10.983+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.630 seconds
[2025-01-13T02:43:40.227+0000] {processor.py:186} INFO - Started process (PID=496) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:43:40.230+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:43:40.237+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:43:40.236+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:43:40.646+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:43:40.687+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:43:40.687+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:43:40.724+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:43:40.724+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:43:40.750+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.543 seconds
[2025-01-13T02:43:41.250+0000] {processor.py:186} INFO - Started process (PID=479) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:43:41.252+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:43:41.254+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:43:41.254+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:43:41.624+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:43:41.651+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:43:41.651+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:43:41.686+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:43:41.686+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:43:41.708+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.463 seconds
[2025-01-13T02:44:11.018+0000] {processor.py:186} INFO - Started process (PID=502) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:44:11.019+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:44:11.021+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:44:11.021+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:44:11.299+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:44:11.322+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:44:11.321+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:44:11.346+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:44:11.346+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:44:11.368+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.357 seconds
[2025-01-13T02:44:11.803+0000] {processor.py:186} INFO - Started process (PID=488) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:44:11.804+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:44:11.806+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:44:11.806+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:44:12.101+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:44:12.124+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:44:12.123+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:44:12.153+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:44:12.152+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:44:12.178+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.383 seconds
[2025-01-13T02:44:41.605+0000] {processor.py:186} INFO - Started process (PID=508) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:44:41.606+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:44:41.609+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:44:41.609+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:44:41.929+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:44:41.951+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:44:41.950+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:44:41.976+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:44:41.976+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:44:41.999+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.401 seconds
[2025-01-13T02:44:42.428+0000] {processor.py:186} INFO - Started process (PID=497) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:44:42.429+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:44:42.432+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:44:42.431+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:44:42.771+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:44:42.796+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:44:42.796+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:44:42.822+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:44:42.822+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:44:42.847+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.426 seconds
[2025-01-13T02:45:12.277+0000] {processor.py:186} INFO - Started process (PID=521) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:45:12.279+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:45:12.282+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:45:12.281+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:45:12.647+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:45:12.674+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:45:12.674+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:45:12.704+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:45:12.704+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:45:12.724+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.455 seconds
[2025-01-13T02:45:13.088+0000] {processor.py:186} INFO - Started process (PID=507) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:45:13.089+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:45:13.091+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:45:13.091+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:45:13.402+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:45:13.434+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:45:13.433+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:45:13.498+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:45:13.498+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:45:13.535+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.452 seconds
[2025-01-13T02:45:13.780+0000] {processor.py:186} INFO - Started process (PID=522) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:45:13.781+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:45:13.784+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:45:13.783+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:45:14.109+0000] {processor.py:186} INFO - Started process (PID=508) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:45:14.110+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:45:14.113+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:45:14.112+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:45:14.119+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:45:14.146+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:45:14.145+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:45:14.171+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:45:14.171+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:45:14.206+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.431 seconds
[2025-01-13T02:45:14.439+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:45:14.467+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:45:14.466+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:45:14.501+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:45:14.501+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:45:14.534+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.432 seconds
[2025-01-13T02:45:44.461+0000] {processor.py:186} INFO - Started process (PID=529) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:45:44.463+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:45:44.465+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:45:44.465+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:45:44.856+0000] {processor.py:186} INFO - Started process (PID=517) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:45:44.857+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:45:44.860+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:45:44.862+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:45:44.862+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:45:44.896+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:45:44.896+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:45:44.926+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:45:44.925+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:45:44.944+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.490 seconds
[2025-01-13T02:45:45.197+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:45:45.224+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:45:45.224+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:45:45.250+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:45:45.249+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:45:45.266+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.423 seconds
[2025-01-13T02:46:15.205+0000] {processor.py:186} INFO - Started process (PID=536) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:46:15.206+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:46:15.208+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:46:15.208+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:46:15.470+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:46:15.493+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:46:15.492+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:46:15.501+0000] {processor.py:186} INFO - Started process (PID=526) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:46:15.501+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:46:15.505+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:46:15.504+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:46:15.520+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:46:15.520+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:46:15.549+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.349 seconds
[2025-01-13T02:46:15.786+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:46:15.810+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:46:15.809+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:46:15.833+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:46:15.833+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:46:15.851+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.356 seconds
[2025-01-13T02:46:45.838+0000] {processor.py:186} INFO - Started process (PID=543) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:46:45.838+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:46:45.841+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:46:45.841+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:46:46.074+0000] {processor.py:186} INFO - Started process (PID=535) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:46:46.075+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:46:46.077+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:46:46.077+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:46:46.148+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:46:46.174+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:46:46.174+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:46:46.202+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:46:46.202+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:46:46.217+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.386 seconds
[2025-01-13T02:46:46.392+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:46:46.416+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:46:46.416+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:46:46.441+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:46:46.441+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:46:46.463+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.402 seconds
[2025-01-13T02:47:16.475+0000] {processor.py:186} INFO - Started process (PID=550) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:47:16.476+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:47:16.481+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:47:16.481+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:47:16.693+0000] {processor.py:186} INFO - Started process (PID=544) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:47:16.694+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:47:16.697+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:47:16.697+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:47:16.777+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:47:16.810+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:47:16.810+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:47:16.837+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:47:16.837+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:47:16.856+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.390 seconds
[2025-01-13T02:47:17.021+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:47:17.044+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:47:17.044+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:47:17.070+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:47:17.070+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:47:17.112+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.427 seconds
[2025-01-13T02:47:17.501+0000] {processor.py:186} INFO - Started process (PID=551) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:47:17.502+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:47:17.506+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:47:17.505+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:47:17.938+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:47:17.972+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:47:17.972+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:47:17.997+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:47:17.997+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:47:18.022+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.531 seconds
[2025-01-13T02:47:28.810+0000] {processor.py:186} INFO - Started process (PID=545) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:47:28.810+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:47:28.813+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:47:28.812+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:47:28.996+0000] {processor.py:186} INFO - Started process (PID=552) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:47:28.997+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:47:29.000+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:47:29.000+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:47:29.145+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:47:29.170+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:47:29.169+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:47:29.201+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:47:29.200+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:47:29.228+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.424 seconds
[2025-01-13T02:47:29.343+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:47:29.375+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:47:29.375+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:47:29.407+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:47:29.407+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:47:29.429+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.441 seconds
[2025-01-13T02:47:42.207+0000] {processor.py:186} INFO - Started process (PID=553) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:47:42.208+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:47:42.211+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:47:42.210+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:47:42.309+0000] {processor.py:186} INFO - Started process (PID=555) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:47:42.310+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:47:42.319+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:47:42.319+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:47:42.578+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:47:42.601+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:47:42.601+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:47:42.647+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:47:42.647+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:47:42.696+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.495 seconds
[2025-01-13T02:47:42.718+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:47:42.750+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:47:42.749+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:47:42.776+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:47:42.776+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:47:42.795+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.494 seconds
[2025-01-13T02:48:12.787+0000] {processor.py:186} INFO - Started process (PID=565) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:48:12.795+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:48:12.806+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:48:12.805+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:48:13.047+0000] {processor.py:186} INFO - Started process (PID=563) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:48:13.053+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:48:13.065+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:48:13.064+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:48:13.274+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:48:13.327+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:48:13.326+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:48:13.369+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:48:13.368+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:48:13.402+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.632 seconds
[2025-01-13T02:48:13.673+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:48:13.702+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:48:13.702+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:48:13.729+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:48:13.729+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:48:13.754+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.715 seconds
[2025-01-13T02:48:43.642+0000] {processor.py:186} INFO - Started process (PID=572) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:48:43.643+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:48:43.646+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:48:43.645+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:48:43.960+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:48:43.986+0000] {processor.py:186} INFO - Started process (PID=565) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:48:43.987+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:48:43.986+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:48:43.987+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:48:43.990+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:48:43.990+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:48:44.017+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:48:44.017+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:48:44.037+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.402 seconds
[2025-01-13T02:48:44.322+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:48:44.346+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:48:44.346+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:48:44.371+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:48:44.371+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:48:44.391+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.411 seconds
[2025-01-13T02:49:14.314+0000] {processor.py:186} INFO - Started process (PID=579) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:49:14.315+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:49:14.318+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:49:14.318+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:49:14.685+0000] {processor.py:186} INFO - Started process (PID=574) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:49:14.691+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:49:14.702+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:49:14.701+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:49:14.713+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:49:14.739+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:49:14.739+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:49:14.764+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:49:14.764+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:49:14.782+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.476 seconds
[2025-01-13T02:49:15.083+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:49:15.111+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:49:15.111+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:49:15.141+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:49:15.140+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:49:15.168+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.502 seconds
[2025-01-13T02:49:45.037+0000] {processor.py:186} INFO - Started process (PID=585) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:49:45.038+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:49:45.040+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:49:45.040+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:49:45.365+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:49:45.389+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:49:45.388+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:49:45.413+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:49:45.412+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:49:45.433+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.403 seconds
[2025-01-13T02:49:45.456+0000] {processor.py:186} INFO - Started process (PID=584) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:49:45.457+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:49:45.460+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:49:45.459+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:49:45.781+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:49:45.812+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:49:45.811+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:49:45.842+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:49:45.841+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:49:45.867+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.418 seconds
[2025-01-13T02:50:15.718+0000] {processor.py:186} INFO - Started process (PID=593) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:50:15.719+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:50:15.721+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:50:15.721+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:50:16.007+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:50:16.031+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:50:16.031+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:50:16.054+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:50:16.053+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:50:16.073+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.361 seconds
[2025-01-13T02:50:16.098+0000] {processor.py:186} INFO - Started process (PID=593) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:50:16.099+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:50:16.101+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:50:16.101+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:50:16.394+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:50:16.419+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:50:16.418+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:50:16.443+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:50:16.442+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:50:16.461+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.368 seconds
[2025-01-13T02:50:46.385+0000] {processor.py:186} INFO - Started process (PID=600) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:50:46.386+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:50:46.388+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:50:46.388+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:50:46.682+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:50:46.712+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:50:46.711+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:50:46.716+0000] {processor.py:186} INFO - Started process (PID=603) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:50:46.717+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:50:46.720+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:50:46.719+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:50:46.737+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:50:46.737+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:50:46.754+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.375 seconds
[2025-01-13T02:50:47.009+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:50:47.033+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:50:47.032+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:50:47.055+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:50:47.055+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:50:47.080+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.369 seconds
[2025-01-13T02:51:17.045+0000] {processor.py:186} INFO - Started process (PID=608) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:51:17.046+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:51:17.048+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:51:17.048+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:51:17.328+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:51:17.354+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:51:17.353+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:51:17.373+0000] {processor.py:186} INFO - Started process (PID=613) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:51:17.374+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:51:17.376+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:51:17.376+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:51:17.385+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:51:17.384+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:51:17.413+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.374 seconds
[2025-01-13T02:51:17.662+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:51:17.685+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:51:17.684+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:51:17.709+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:51:17.709+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:51:17.732+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.365 seconds
[2025-01-13T02:51:47.689+0000] {processor.py:186} INFO - Started process (PID=615) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:51:47.690+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:51:47.692+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:51:47.692+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:51:47.976+0000] {processor.py:186} INFO - Started process (PID=622) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:51:47.977+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:51:47.980+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:51:47.980+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:51:48.031+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:51:48.058+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:51:48.057+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:51:48.084+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:51:48.084+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:51:48.116+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.433 seconds
[2025-01-13T02:51:48.304+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:51:48.335+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:51:48.334+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:51:48.358+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:51:48.358+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:51:48.375+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.406 seconds
[2025-01-13T02:52:18.369+0000] {processor.py:186} INFO - Started process (PID=623) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:52:18.370+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:52:18.373+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:52:18.372+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:52:18.591+0000] {processor.py:186} INFO - Started process (PID=631) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:52:18.592+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:52:18.594+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:52:18.594+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:52:18.670+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:52:18.696+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:52:18.695+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:52:18.723+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:52:18.723+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:52:18.743+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.380 seconds
[2025-01-13T02:52:18.903+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:52:18.928+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:52:18.927+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:52:18.952+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:52:18.952+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:52:18.976+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.392 seconds
[2025-01-13T02:52:48.997+0000] {processor.py:186} INFO - Started process (PID=630) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:52:48.998+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:52:49.001+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:52:49.000+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:52:49.221+0000] {processor.py:186} INFO - Started process (PID=640) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:52:49.222+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:52:49.224+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:52:49.224+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:52:49.278+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:52:49.303+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:52:49.302+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:52:49.328+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:52:49.328+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:52:49.355+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.363 seconds
[2025-01-13T02:52:49.528+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:52:49.553+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:52:49.552+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:52:49.575+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:52:49.575+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:52:49.601+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.386 seconds
[2025-01-13T02:53:19.577+0000] {processor.py:186} INFO - Started process (PID=637) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:53:19.578+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:53:19.580+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:53:19.580+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:53:19.822+0000] {processor.py:186} INFO - Started process (PID=649) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:53:19.823+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:53:19.826+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:53:19.825+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:53:19.907+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:53:19.931+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:53:19.931+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:53:19.962+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:53:19.961+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:53:19.981+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.410 seconds
[2025-01-13T02:53:20.188+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:53:20.213+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:53:20.213+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:53:20.243+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:53:20.242+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:53:20.265+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.452 seconds
[2025-01-13T02:53:50.233+0000] {processor.py:186} INFO - Started process (PID=644) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:53:50.234+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:53:50.237+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:53:50.236+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:53:50.513+0000] {processor.py:186} INFO - Started process (PID=658) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:53:50.514+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:53:50.516+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:53:50.516+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:53:50.517+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:53:50.544+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:53:50.544+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:53:50.567+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:53:50.567+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:53:50.589+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.363 seconds
[2025-01-13T02:53:50.804+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:53:50.827+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:53:50.827+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:53:50.849+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:53:50.849+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:53:50.871+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.365 seconds
[2025-01-13T02:54:20.836+0000] {processor.py:186} INFO - Started process (PID=651) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:54:20.837+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:54:20.839+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:54:20.839+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:54:21.112+0000] {processor.py:186} INFO - Started process (PID=666) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:54:21.113+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:54:21.116+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:54:21.116+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:54:21.135+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:54:21.164+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:54:21.164+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:54:21.191+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:54:21.190+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:54:21.217+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.387 seconds
[2025-01-13T02:54:21.435+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:54:21.458+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:54:21.457+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:54:21.481+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:54:21.481+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:54:21.504+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.400 seconds
[2025-01-13T02:54:51.498+0000] {processor.py:186} INFO - Started process (PID=658) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:54:51.499+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:54:51.501+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:54:51.501+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:54:51.808+0000] {processor.py:186} INFO - Started process (PID=675) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:54:51.818+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:54:51.823+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:54:51.822+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:54:51.846+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:54:51.900+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:54:51.899+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:54:51.956+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:54:51.956+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:54:52.009+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.518 seconds
[2025-01-13T02:54:52.341+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:54:52.400+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:54:52.399+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:54:52.449+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:54:52.449+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:54:52.480+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.689 seconds
[2025-01-13T02:55:22.234+0000] {processor.py:186} INFO - Started process (PID=665) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:55:22.234+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:55:22.237+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:55:22.237+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:55:22.524+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:55:22.547+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:55:22.546+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:55:22.568+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:55:22.567+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:55:22.593+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.367 seconds
[2025-01-13T02:55:22.594+0000] {processor.py:186} INFO - Started process (PID=677) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:55:22.595+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:55:22.598+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:55:22.597+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:55:22.891+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:55:22.914+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:55:22.914+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:55:22.938+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:55:22.938+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:55:22.959+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.371 seconds
[2025-01-13T02:55:52.893+0000] {processor.py:186} INFO - Started process (PID=672) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:55:52.893+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:55:52.896+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:55:52.895+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:55:53.188+0000] {processor.py:186} INFO - Started process (PID=686) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:55:53.189+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:55:53.192+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:55:53.191+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:55:53.268+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:55:53.293+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:55:53.292+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:55:53.326+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:55:53.326+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:55:53.352+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.466 seconds
[2025-01-13T02:55:53.595+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:55:53.626+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:55:53.626+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:55:53.659+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:55:53.658+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:55:53.687+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.506 seconds
[2025-01-13T02:56:23.602+0000] {processor.py:186} INFO - Started process (PID=679) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:56:23.605+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:56:23.608+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:56:23.607+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:56:23.959+0000] {processor.py:186} INFO - Started process (PID=695) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:56:23.965+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:56:23.969+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:56:23.969+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:56:24.243+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:56:24.296+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:56:24.295+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:56:24.352+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:56:24.351+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:56:24.399+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.811 seconds
[2025-01-13T02:56:24.604+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:56:24.648+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:56:24.648+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:56:24.690+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:56:24.690+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:56:24.711+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.760 seconds
[2025-01-13T02:56:54.590+0000] {processor.py:186} INFO - Started process (PID=686) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:56:54.591+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:56:54.593+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:56:54.593+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:56:54.883+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:56:54.905+0000] {processor.py:186} INFO - Started process (PID=704) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:56:54.907+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:56:54.907+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:56:54.906+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:56:54.908+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:56:54.908+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:56:54.933+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:56:54.932+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:56:54.950+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.366 seconds
[2025-01-13T02:56:55.225+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:56:55.248+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:56:55.248+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:56:55.272+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:56:55.272+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:56:55.294+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.396 seconds
[2025-01-13T02:57:25.185+0000] {processor.py:186} INFO - Started process (PID=693) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:57:25.186+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:57:25.188+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:57:25.188+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:57:25.494+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:57:25.521+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:57:25.521+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:57:25.535+0000] {processor.py:186} INFO - Started process (PID=713) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:57:25.536+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:57:25.539+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:57:25.538+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:57:25.549+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:57:25.549+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:57:25.565+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.387 seconds
[2025-01-13T02:57:25.831+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:57:25.856+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:57:25.855+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:57:25.880+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:57:25.879+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:57:25.896+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.368 seconds
[2025-01-13T02:57:55.808+0000] {processor.py:186} INFO - Started process (PID=700) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:57:55.810+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:57:55.816+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:57:55.815+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:57:56.120+0000] {processor.py:186} INFO - Started process (PID=722) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:57:56.122+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:57:56.125+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:57:56.125+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:57:56.211+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:57:56.260+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:57:56.259+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:57:56.323+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:57:56.322+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:57:56.357+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.561 seconds
[2025-01-13T02:57:56.614+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:57:56.660+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:57:56.659+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:57:56.703+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:57:56.703+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:57:56.731+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.619 seconds
[2025-01-13T02:58:26.626+0000] {processor.py:186} INFO - Started process (PID=706) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:58:26.627+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:58:26.629+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:58:26.628+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:58:26.936+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:58:26.999+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:58:26.998+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:58:27.039+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:58:27.039+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:58:27.043+0000] {processor.py:186} INFO - Started process (PID=731) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:58:27.045+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:58:27.048+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:58:27.048+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:58:27.066+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.446 seconds
[2025-01-13T02:58:27.429+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:58:27.457+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:58:27.457+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:58:27.487+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:58:27.486+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:58:27.512+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.479 seconds
[2025-01-13T02:58:57.239+0000] {processor.py:186} INFO - Started process (PID=713) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:58:57.240+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:58:57.242+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:58:57.242+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:58:57.520+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:58:57.543+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:58:57.542+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:58:57.568+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:58:57.568+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:58:57.596+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.364 seconds
[2025-01-13T02:58:57.750+0000] {processor.py:186} INFO - Started process (PID=740) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:58:57.751+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:58:57.753+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:58:57.753+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:58:58.037+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:58:58.062+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:58:58.061+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:58:58.084+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:58:58.084+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:58:58.110+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.365 seconds
[2025-01-13T02:59:27.855+0000] {processor.py:186} INFO - Started process (PID=720) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:59:27.856+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:59:27.859+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:59:27.859+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:59:28.253+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:59:28.283+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:59:28.282+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:59:28.310+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:59:28.310+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:59:28.330+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.484 seconds
[2025-01-13T02:59:28.344+0000] {processor.py:186} INFO - Started process (PID=749) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:59:28.346+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:59:28.349+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:59:28.348+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:59:28.693+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:59:28.726+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:59:28.726+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:59:28.756+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:59:28.756+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:59:28.784+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.447 seconds
[2025-01-13T02:59:58.616+0000] {processor.py:186} INFO - Started process (PID=728) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:59:58.617+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:59:58.622+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:59:58.622+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:59:58.946+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:59:58.972+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:59:58.971+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:59:59.003+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:59:59.003+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:59:59.028+0000] {processor.py:186} INFO - Started process (PID=758) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T02:59:59.029+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T02:59:59.032+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:59:59.032+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:59:59.042+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.433 seconds
[2025-01-13T02:59:59.412+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T02:59:59.439+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:59:59.439+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T02:59:59.466+0000] {logging_mixin.py:190} INFO - [2025-01-13T02:59:59.466+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T02:59:59.487+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.466 seconds
[2025-01-13T03:00:29.276+0000] {processor.py:186} INFO - Started process (PID=735) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:00:29.277+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:00:29.280+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:00:29.280+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:00:29.584+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:00:29.607+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:00:29.607+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:00:29.630+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:00:29.630+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:00:29.650+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.380 seconds
[2025-01-13T03:00:29.740+0000] {processor.py:186} INFO - Started process (PID=767) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:00:29.741+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:00:29.743+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:00:29.743+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:00:30.043+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:00:30.067+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:00:30.066+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:00:30.091+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:00:30.091+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:00:30.116+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.382 seconds
[2025-01-13T03:00:59.896+0000] {processor.py:186} INFO - Started process (PID=742) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:00:59.897+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:00:59.899+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:00:59.899+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:01:00.175+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:01:00.196+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:01:00.196+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:01:00.222+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:01:00.222+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:01:00.246+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.355 seconds
[2025-01-13T03:01:00.358+0000] {processor.py:186} INFO - Started process (PID=776) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:01:00.359+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:01:00.361+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:01:00.360+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:01:00.645+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:01:00.670+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:01:00.670+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:01:00.692+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:01:00.692+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:01:00.718+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.366 seconds
[2025-01-13T03:01:30.487+0000] {processor.py:186} INFO - Started process (PID=750) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:01:30.490+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:01:30.493+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:01:30.493+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:01:30.840+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:01:30.866+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:01:30.865+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:01:30.889+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:01:30.889+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:01:30.915+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.441 seconds
[2025-01-13T03:01:31.019+0000] {processor.py:186} INFO - Started process (PID=785) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:01:31.020+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:01:31.023+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:01:31.022+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:01:31.367+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:01:31.393+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:01:31.393+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:01:31.430+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:01:31.429+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:01:31.477+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.466 seconds
[2025-01-13T03:02:01.254+0000] {processor.py:186} INFO - Started process (PID=757) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:02:01.255+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:02:01.257+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:02:01.257+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:02:01.531+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:02:01.552+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:02:01.552+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:02:01.589+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:02:01.589+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:02:01.606+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.359 seconds
[2025-01-13T03:02:01.770+0000] {processor.py:186} INFO - Started process (PID=787) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:02:01.771+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:02:01.773+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:02:01.773+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:02:02.037+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:02:02.061+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:02:02.060+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:02:02.082+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:02:02.082+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:02:02.106+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.341 seconds
[2025-01-13T03:02:31.894+0000] {processor.py:186} INFO - Started process (PID=765) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:02:31.895+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:02:31.898+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:02:31.897+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:02:32.172+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:02:32.196+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:02:32.196+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:02:32.220+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:02:32.220+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:02:32.246+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.358 seconds
[2025-01-13T03:02:32.394+0000] {processor.py:186} INFO - Started process (PID=796) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:02:32.394+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:02:32.397+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:02:32.396+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:02:32.677+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:02:32.700+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:02:32.700+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:02:32.724+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:02:32.724+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:02:32.746+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.358 seconds
[2025-01-13T03:03:02.529+0000] {processor.py:186} INFO - Started process (PID=772) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:03:02.530+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:03:02.532+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:03:02.532+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:03:02.824+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:03:02.849+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:03:02.848+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:03:02.875+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:03:02.875+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:03:02.903+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.379 seconds
[2025-01-13T03:03:03.014+0000] {processor.py:186} INFO - Started process (PID=805) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:03:03.015+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:03:03.018+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:03:03.017+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:03:03.302+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:03:03.325+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:03:03.324+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:03:03.349+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:03:03.348+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:03:03.374+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.367 seconds
[2025-01-13T03:03:33.179+0000] {processor.py:186} INFO - Started process (PID=779) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:03:33.180+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:03:33.182+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:03:33.182+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:03:33.464+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:03:33.489+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:03:33.488+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:03:33.515+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:03:33.515+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:03:33.546+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.373 seconds
[2025-01-13T03:03:33.614+0000] {processor.py:186} INFO - Started process (PID=814) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:03:33.615+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:03:33.618+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:03:33.618+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:03:33.950+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:03:33.974+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:03:33.974+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:03:33.998+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:03:33.998+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:03:34.025+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.418 seconds
[2025-01-13T03:04:03.804+0000] {processor.py:186} INFO - Started process (PID=787) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:04:03.805+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:04:03.808+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:04:03.807+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:04:04.153+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:04:04.184+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:04:04.184+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:04:04.217+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:04:04.217+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:04:04.247+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.457 seconds
[2025-01-13T03:04:04.338+0000] {processor.py:186} INFO - Started process (PID=823) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:04:04.339+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:04:04.343+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:04:04.343+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:04:04.776+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:04:04.811+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:04:04.810+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:04:04.836+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:04:04.836+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:04:04.864+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.534 seconds
[2025-01-13T03:04:34.513+0000] {processor.py:186} INFO - Started process (PID=794) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:04:34.514+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:04:34.516+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:04:34.516+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:04:34.800+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:04:34.823+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:04:34.822+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:04:34.852+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:04:34.851+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:04:34.876+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.370 seconds
[2025-01-13T03:04:35.134+0000] {processor.py:186} INFO - Started process (PID=832) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:04:35.135+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:04:35.137+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:04:35.137+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:04:35.443+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:04:35.469+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:04:35.468+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:04:35.498+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:04:35.498+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:04:35.521+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.394 seconds
[2025-01-13T03:05:05.139+0000] {processor.py:186} INFO - Started process (PID=801) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:05:05.140+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:05:05.142+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:05:05.141+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:05:05.412+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:05:05.434+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:05:05.433+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:05:05.456+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:05:05.455+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:05:05.473+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.340 seconds
[2025-01-13T03:05:05.760+0000] {processor.py:186} INFO - Started process (PID=842) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:05:05.760+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:05:05.763+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:05:05.762+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:05:06.044+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:05:06.067+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:05:06.066+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:05:06.089+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:05:06.088+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:05:06.111+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.358 seconds
[2025-01-13T03:05:18.629+0000] {processor.py:186} INFO - Started process (PID=809) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:05:18.630+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:05:18.632+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:05:18.632+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:05:18.877+0000] {processor.py:186} INFO - Started process (PID=843) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:05:18.878+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:05:18.880+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:05:18.880+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:05:18.908+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:05:18.929+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:05:18.928+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:05:18.952+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:05:18.952+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:05:18.984+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.361 seconds
[2025-01-13T03:05:19.177+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:05:19.200+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:05:19.199+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:05:19.223+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:05:19.223+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:05:19.242+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.372 seconds
[2025-01-13T03:05:49.184+0000] {processor.py:186} INFO - Started process (PID=816) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:05:49.185+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:05:49.187+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:05:49.187+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:05:49.450+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:05:49.455+0000] {processor.py:186} INFO - Started process (PID=853) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:05:49.456+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:05:49.459+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:05:49.459+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:05:49.475+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:05:49.474+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:05:49.497+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:05:49.497+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:05:49.525+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.348 seconds
[2025-01-13T03:05:49.745+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:05:49.767+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:05:49.767+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:05:49.792+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:05:49.792+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:05:49.808+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.366 seconds
[2025-01-13T03:06:19.811+0000] {processor.py:186} INFO - Started process (PID=823) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:06:19.812+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:06:19.815+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:06:19.814+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:06:20.068+0000] {processor.py:186} INFO - Started process (PID=863) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:06:20.069+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:06:20.071+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:06:20.071+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:06:20.108+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:06:20.130+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:06:20.129+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:06:20.152+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:06:20.152+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:06:20.170+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.364 seconds
[2025-01-13T03:06:20.371+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:06:20.396+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:06:20.395+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:06:20.420+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:06:20.419+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:06:20.443+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.383 seconds
[2025-01-13T03:06:50.422+0000] {processor.py:186} INFO - Started process (PID=830) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:06:50.423+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:06:50.426+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:06:50.425+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:06:50.694+0000] {processor.py:186} INFO - Started process (PID=872) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:06:50.695+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:06:50.698+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:06:50.697+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:06:50.701+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:06:50.733+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:06:50.733+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:06:50.755+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:06:50.754+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:06:50.775+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.358 seconds
[2025-01-13T03:06:50.986+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:06:51.008+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:06:51.007+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:06:51.031+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:06:51.030+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:06:51.048+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.361 seconds
[2025-01-13T03:07:21.059+0000] {processor.py:186} INFO - Started process (PID=837) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:07:21.060+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:07:21.062+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:07:21.062+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:07:21.338+0000] {processor.py:186} INFO - Started process (PID=881) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:07:21.340+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:07:21.346+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:07:21.346+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:07:21.422+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:07:21.463+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:07:21.462+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:07:21.516+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:07:21.516+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:07:21.541+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.488 seconds
[2025-01-13T03:07:21.816+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:07:21.839+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:07:21.839+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:07:21.867+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:07:21.867+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:07:21.892+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.566 seconds
[2025-01-13T03:07:51.878+0000] {processor.py:186} INFO - Started process (PID=844) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:07:51.880+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:07:51.883+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:07:51.882+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:07:52.202+0000] {processor.py:186} INFO - Started process (PID=891) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:07:52.203+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:07:52.207+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:07:52.206+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:07:52.210+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:07:52.237+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:07:52.236+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:07:52.265+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:07:52.265+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:07:52.286+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.416 seconds
[2025-01-13T03:07:52.593+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:07:52.637+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:07:52.637+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:07:52.678+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:07:52.676+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:07:52.709+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.515 seconds
[2025-01-13T03:08:22.585+0000] {processor.py:186} INFO - Started process (PID=852) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:08:22.585+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:08:22.588+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:08:22.587+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:08:22.857+0000] {processor.py:186} INFO - Started process (PID=900) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:08:22.858+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:08:22.860+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:08:22.860+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:08:22.872+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:08:22.894+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:08:22.894+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:08:22.915+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:08:22.915+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:08:22.937+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.359 seconds
[2025-01-13T03:08:23.144+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:08:23.167+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:08:23.166+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:08:23.188+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:08:23.187+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:08:23.203+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.352 seconds
[2025-01-13T03:08:53.251+0000] {processor.py:186} INFO - Started process (PID=859) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:08:53.252+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:08:53.255+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:08:53.255+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:08:53.272+0000] {processor.py:186} INFO - Started process (PID=909) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:08:53.273+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:08:53.275+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:08:53.275+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:08:53.582+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:08:53.606+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:08:53.605+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:08:53.637+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:08:53.636+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:08:53.657+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:08:53.664+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.420 seconds
[2025-01-13T03:08:53.689+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:08:53.689+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:08:53.717+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:08:53.717+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:08:53.738+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.473 seconds
[2025-01-13T03:09:23.939+0000] {processor.py:186} INFO - Started process (PID=866) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:09:23.940+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:09:23.942+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:09:23.942+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:09:23.973+0000] {processor.py:186} INFO - Started process (PID=919) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:09:23.975+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:09:23.977+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:09:23.977+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:09:24.262+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:09:24.286+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:09:24.286+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:09:24.312+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:09:24.311+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:09:24.328+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:09:24.345+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.412 seconds
[2025-01-13T03:09:24.360+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:09:24.359+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:09:24.387+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:09:24.387+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:09:24.413+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.447 seconds
[2025-01-13T03:09:54.605+0000] {processor.py:186} INFO - Started process (PID=873) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:09:54.606+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:09:54.608+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:09:54.608+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:09:54.728+0000] {processor.py:186} INFO - Started process (PID=928) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:09:54.729+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:09:54.732+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:09:54.731+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:09:54.926+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:09:54.950+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:09:54.949+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:09:54.972+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:09:54.972+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:09:54.993+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.395 seconds
[2025-01-13T03:09:55.049+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:09:55.073+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:09:55.072+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:09:55.096+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:09:55.096+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:09:55.113+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.391 seconds
[2025-01-13T03:10:25.251+0000] {processor.py:186} INFO - Started process (PID=880) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:10:25.252+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:10:25.255+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:10:25.254+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:10:25.396+0000] {processor.py:186} INFO - Started process (PID=937) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:10:25.397+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:10:25.399+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:10:25.399+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:10:25.587+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:10:25.608+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:10:25.608+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:10:25.633+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:10:25.633+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:10:25.657+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.411 seconds
[2025-01-13T03:10:25.736+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:10:25.761+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:10:25.760+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:10:25.784+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:10:25.784+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:10:25.804+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.415 seconds
[2025-01-13T03:10:55.945+0000] {processor.py:186} INFO - Started process (PID=887) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:10:55.946+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:10:55.950+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:10:55.949+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:10:56.056+0000] {processor.py:186} INFO - Started process (PID=946) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:10:56.057+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:10:56.060+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:10:56.059+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:10:56.279+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:10:56.310+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:10:56.308+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:10:56.343+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:10:56.342+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:10:56.369+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.430 seconds
[2025-01-13T03:10:56.422+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:10:56.448+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:10:56.447+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:10:56.474+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:10:56.474+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:10:56.496+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.448 seconds
[2025-01-13T03:11:26.680+0000] {processor.py:186} INFO - Started process (PID=895) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:11:26.681+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:11:26.684+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:11:26.683+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:11:26.772+0000] {processor.py:186} INFO - Started process (PID=955) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:11:26.773+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:11:26.775+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:11:26.775+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:11:26.993+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:11:27.025+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:11:27.024+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:11:27.050+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:11:27.050+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:11:27.067+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.392 seconds
[2025-01-13T03:11:27.151+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:11:27.174+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:11:27.174+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:11:27.196+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:11:27.195+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:11:27.214+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.448 seconds
[2025-01-13T03:11:57.353+0000] {processor.py:186} INFO - Started process (PID=902) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:11:57.354+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:11:57.357+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:11:57.356+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:11:57.544+0000] {processor.py:186} INFO - Started process (PID=964) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:11:57.545+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:11:57.547+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:11:57.547+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:11:57.664+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:11:57.689+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:11:57.688+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:11:57.712+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:11:57.712+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:11:57.729+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.383 seconds
[2025-01-13T03:11:57.848+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:11:57.871+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:11:57.870+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:11:57.897+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:11:57.897+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:11:57.917+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.381 seconds
[2025-01-13T03:12:28.020+0000] {processor.py:186} INFO - Started process (PID=909) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:12:28.021+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:12:28.024+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:12:28.023+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:12:28.192+0000] {processor.py:186} INFO - Started process (PID=972) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:12:28.193+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:12:28.196+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:12:28.196+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:12:28.363+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:12:28.387+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:12:28.387+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:12:28.413+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:12:28.413+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:12:28.436+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.421 seconds
[2025-01-13T03:12:28.649+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:12:28.677+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:12:28.676+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:12:28.706+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:12:28.706+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:12:28.728+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.552 seconds
[2025-01-13T03:12:58.732+0000] {processor.py:186} INFO - Started process (PID=916) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:12:58.733+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:12:58.735+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:12:58.735+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:12:59.005+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:12:59.027+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:12:59.027+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:12:59.041+0000] {processor.py:186} INFO - Started process (PID=974) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:12:59.043+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:12:59.046+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:12:59.045+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:12:59.052+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:12:59.052+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:12:59.071+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.345 seconds
[2025-01-13T03:12:59.332+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:12:59.357+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:12:59.356+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:12:59.380+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:12:59.380+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:12:59.400+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.367 seconds
[2025-01-13T03:13:29.370+0000] {processor.py:186} INFO - Started process (PID=923) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:13:29.371+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:13:29.374+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:13:29.373+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:13:29.666+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:13:29.691+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:13:29.690+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:13:29.711+0000] {processor.py:186} INFO - Started process (PID=983) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:13:29.712+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:13:29.715+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:13:29.714+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:13:29.720+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:13:29.720+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:13:29.751+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.387 seconds
[2025-01-13T03:13:30.032+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:13:30.055+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:13:30.054+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:13:30.079+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:13:30.079+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:13:30.099+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.395 seconds
[2025-01-13T03:14:00.031+0000] {processor.py:186} INFO - Started process (PID=930) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:14:00.032+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:14:00.034+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:14:00.034+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:14:00.299+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:14:00.323+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:14:00.322+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:14:00.345+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:14:00.345+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:14:00.380+0000] {processor.py:186} INFO - Started process (PID=993) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:14:00.381+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:14:00.383+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.357 seconds
[2025-01-13T03:14:00.385+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:14:00.383+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:14:00.668+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:14:00.689+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:14:00.689+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:14:00.712+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:14:00.712+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:14:00.729+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.355 seconds
[2025-01-13T03:14:30.635+0000] {processor.py:186} INFO - Started process (PID=937) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:14:30.636+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:14:30.638+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:14:30.638+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:14:30.910+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:14:30.931+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:14:30.931+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:14:30.952+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:14:30.952+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:14:30.967+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.338 seconds
[2025-01-13T03:14:31.040+0000] {processor.py:186} INFO - Started process (PID=1002) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:14:31.041+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:14:31.043+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:14:31.043+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:14:31.332+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:14:31.355+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:14:31.355+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:14:31.377+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:14:31.377+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:14:31.393+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.359 seconds
[2025-01-13T03:15:01.317+0000] {processor.py:186} INFO - Started process (PID=945) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:15:01.318+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:15:01.321+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:15:01.321+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:15:01.582+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:15:01.604+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:15:01.603+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:15:01.625+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:15:01.625+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:15:01.654+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.342 seconds
[2025-01-13T03:15:01.664+0000] {processor.py:186} INFO - Started process (PID=1012) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:15:01.665+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:15:01.667+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:15:01.667+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:15:01.952+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:15:01.975+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:15:01.975+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:15:01.999+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:15:01.998+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:15:02.017+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.360 seconds
[2025-01-13T03:15:31.921+0000] {processor.py:186} INFO - Started process (PID=953) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:15:31.922+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:15:31.925+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:15:31.924+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:15:32.291+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:15:32.312+0000] {processor.py:186} INFO - Started process (PID=1021) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:15:32.313+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:15:32.316+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:15:32.315+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:15:32.316+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:15:32.316+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:15:32.345+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:15:32.344+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:15:32.365+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.451 seconds
[2025-01-13T03:15:32.693+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:15:32.719+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:15:32.718+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:15:32.761+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:15:32.761+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:15:32.780+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.485 seconds
[2025-01-13T03:16:02.737+0000] {processor.py:186} INFO - Started process (PID=960) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:16:02.740+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:16:02.747+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:16:02.746+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:16:03.031+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:16:03.064+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:16:03.063+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:16:03.064+0000] {processor.py:186} INFO - Started process (PID=1030) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:16:03.065+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:16:03.068+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:16:03.068+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:16:03.092+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:16:03.092+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:16:03.109+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.388 seconds
[2025-01-13T03:16:03.367+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:16:03.389+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:16:03.389+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:16:03.412+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:16:03.412+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:16:03.441+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.386 seconds
[2025-01-13T03:16:33.348+0000] {processor.py:186} INFO - Started process (PID=966) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:16:33.349+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:16:33.352+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:16:33.351+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:16:33.620+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:16:33.641+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:16:33.640+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:16:33.662+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:16:33.661+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:16:33.683+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.341 seconds
[2025-01-13T03:16:33.707+0000] {processor.py:186} INFO - Started process (PID=1039) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:16:33.708+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:16:33.710+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:16:33.710+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:16:33.994+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:16:34.022+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:16:34.021+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:16:34.045+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:16:34.045+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:16:34.068+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.368 seconds
[2025-01-13T03:17:04.024+0000] {processor.py:186} INFO - Started process (PID=973) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:17:04.025+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:17:04.031+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:17:04.030+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:17:04.328+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:17:04.337+0000] {processor.py:186} INFO - Started process (PID=1048) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:17:04.338+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:17:04.340+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:17:04.340+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:17:04.354+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:17:04.353+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:17:04.375+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:17:04.374+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:17:04.392+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.375 seconds
[2025-01-13T03:17:04.638+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:17:04.660+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:17:04.660+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:17:04.683+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:17:04.683+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:17:04.712+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.384 seconds
[2025-01-13T03:17:34.636+0000] {processor.py:186} INFO - Started process (PID=980) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:17:34.637+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:17:34.639+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:17:34.638+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:17:34.933+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:17:34.954+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:17:34.954+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:17:34.977+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:17:34.977+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:17:35.000+0000] {processor.py:186} INFO - Started process (PID=1057) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:17:35.002+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:17:35.005+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:17:35.004+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:17:35.009+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.379 seconds
[2025-01-13T03:17:35.301+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:17:35.326+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:17:35.326+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:17:35.351+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:17:35.351+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:17:35.371+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.377 seconds
[2025-01-13T03:18:05.277+0000] {processor.py:186} INFO - Started process (PID=987) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:18:05.278+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:18:05.281+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:18:05.280+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:18:05.557+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:18:05.583+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:18:05.582+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:18:05.610+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:18:05.610+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:18:05.624+0000] {processor.py:186} INFO - Started process (PID=1066) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:18:05.626+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:18:05.630+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:18:05.630+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:18:05.632+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.362 seconds
[2025-01-13T03:18:05.921+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:18:05.944+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:18:05.943+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:18:05.966+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:18:05.966+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:18:05.983+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.367 seconds
[2025-01-13T03:18:35.923+0000] {processor.py:186} INFO - Started process (PID=995) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:18:35.924+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:18:35.927+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:18:35.926+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:18:36.225+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:18:36.249+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:18:36.249+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:18:36.271+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:18:36.271+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:18:36.289+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.372 seconds
[2025-01-13T03:18:36.288+0000] {processor.py:186} INFO - Started process (PID=1075) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:18:36.291+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:18:36.295+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:18:36.294+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:18:36.605+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:18:36.633+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:18:36.632+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:18:36.660+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:18:36.659+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:18:36.685+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.404 seconds
[2025-01-13T03:19:06.616+0000] {processor.py:186} INFO - Started process (PID=1002) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:19:06.617+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:19:06.620+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:19:06.620+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:19:06.912+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:19:06.933+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:19:06.932+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:19:06.953+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:19:06.952+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:19:06.975+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.368 seconds
[2025-01-13T03:19:06.991+0000] {processor.py:186} INFO - Started process (PID=1084) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:19:06.993+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:19:06.996+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:19:06.996+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:19:07.283+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:19:07.306+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:19:07.306+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:19:07.328+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:19:07.327+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:19:07.359+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.374 seconds
[2025-01-13T03:19:37.219+0000] {processor.py:186} INFO - Started process (PID=1009) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:19:37.220+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:19:37.223+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:19:37.223+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:19:37.532+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:19:37.558+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:19:37.558+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:19:37.605+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:19:37.605+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:19:37.622+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.411 seconds
[2025-01-13T03:19:37.654+0000] {processor.py:186} INFO - Started process (PID=1092) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T03:19:37.655+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T03:19:37.658+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:19:37.658+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:19:37.984+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T03:19:38.011+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:19:38.010+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T03:19:38.043+0000] {logging_mixin.py:190} INFO - [2025-01-13T03:19:38.042+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T03:19:38.062+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.414 seconds
[2025-01-13T09:54:10.060+0000] {processor.py:186} INFO - Started process (PID=63) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T09:54:10.068+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T09:54:10.079+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:54:10.078+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T09:54:11.882+0000] {logging_mixin.py:190} WARNING - /opt/airflow/dags/crawl_data.py:134 SyntaxWarning: invalid escape sequence '\T'
[2025-01-13T09:54:11.914+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T09:54:12.321+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:54:12.319+0000] {override.py:1911} INFO - Created Permission View: can read on DAG:topcv_scraper
[2025-01-13T09:54:12.336+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:54:12.335+0000] {override.py:1911} INFO - Created Permission View: can edit on DAG:topcv_scraper
[2025-01-13T09:54:12.345+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:54:12.345+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG:topcv_scraper
[2025-01-13T09:54:12.354+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:54:12.353+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:topcv_scraper
[2025-01-13T09:54:12.361+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:54:12.361+0000] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:topcv_scraper
[2025-01-13T09:54:12.369+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:54:12.369+0000] {override.py:1911} INFO - Created Permission View: can create on DAG Run:topcv_scraper
[2025-01-13T09:54:12.377+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:54:12.377+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:topcv_scraper
[2025-01-13T09:54:12.379+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:54:12.379+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T09:54:12.400+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:54:12.399+0000] {dag.py:3262} INFO - Creating ORM DAG for topcv_scraper
[2025-01-13T09:54:12.415+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:54:12.415+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-12 00:00:00+00:00, run_after=2025-01-13 00:00:00+00:00
[2025-01-13T09:54:12.449+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 2.407 seconds
[2025-01-13T09:54:42.696+0000] {processor.py:186} INFO - Started process (PID=70) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T09:54:42.699+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T09:54:42.704+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:54:42.703+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T09:54:43.173+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T09:54:43.194+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:54:43.194+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T09:54:43.216+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:54:43.216+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-12 00:00:00+00:00, run_after=2025-01-13 00:00:00+00:00
[2025-01-13T09:54:43.232+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.547 seconds
[2025-01-13T09:55:13.451+0000] {processor.py:186} INFO - Started process (PID=77) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T09:55:13.452+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T09:55:13.454+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:55:13.454+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T09:55:13.849+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T09:55:13.869+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:55:13.869+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T09:55:13.890+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:55:13.890+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-12 00:00:00+00:00, run_after=2025-01-13 00:00:00+00:00
[2025-01-13T09:55:13.909+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.464 seconds
[2025-01-13T09:55:44.110+0000] {processor.py:186} INFO - Started process (PID=84) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T09:55:44.112+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T09:55:44.115+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:55:44.114+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T09:55:44.594+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T09:55:44.618+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:55:44.617+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T09:55:44.638+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:55:44.638+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-12 00:00:00+00:00, run_after=2025-01-13 00:00:00+00:00
[2025-01-13T09:55:44.667+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.563 seconds
[2025-01-13T09:56:14.912+0000] {processor.py:186} INFO - Started process (PID=91) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T09:56:14.913+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T09:56:14.916+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:56:14.916+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T09:56:15.316+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T09:56:15.335+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:56:15.335+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T09:56:15.355+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:56:15.355+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T09:56:15.377+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.471 seconds
[2025-01-13T09:56:45.553+0000] {processor.py:186} INFO - Started process (PID=98) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T09:56:45.554+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T09:56:45.557+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:56:45.557+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T09:56:45.952+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T09:56:45.972+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:56:45.971+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T09:56:45.992+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:56:45.992+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T09:56:46.008+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.461 seconds
[2025-01-13T09:57:16.251+0000] {processor.py:186} INFO - Started process (PID=105) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T09:57:16.252+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T09:57:16.257+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:57:16.256+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T09:57:16.777+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T09:57:16.803+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:57:16.802+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T09:57:16.828+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:57:16.828+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T09:57:16.856+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.613 seconds
[2025-01-13T09:57:47.023+0000] {processor.py:186} INFO - Started process (PID=112) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T09:57:47.024+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T09:57:47.030+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:57:47.029+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T09:57:47.796+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T09:57:47.835+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:57:47.834+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T09:57:47.865+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:57:47.864+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T09:57:47.924+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.932 seconds
[2025-01-13T09:58:18.242+0000] {processor.py:186} INFO - Started process (PID=119) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T09:58:18.244+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T09:58:18.247+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:58:18.247+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T09:58:19.190+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T09:58:19.238+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:58:19.238+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T09:58:19.274+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:58:19.274+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T09:58:19.323+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 1.099 seconds
[2025-01-13T09:58:49.493+0000] {processor.py:186} INFO - Started process (PID=126) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T09:58:49.494+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T09:58:49.497+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:58:49.496+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T09:58:50.136+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T09:58:50.166+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:58:50.166+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T09:58:50.196+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:58:50.196+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T09:58:50.243+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.758 seconds
[2025-01-13T09:59:20.575+0000] {processor.py:186} INFO - Started process (PID=138) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T09:59:20.576+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T09:59:20.578+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:59:20.578+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T09:59:21.066+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T09:59:21.089+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:59:21.088+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T09:59:21.112+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:59:21.112+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T09:59:21.134+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.566 seconds
[2025-01-13T09:59:51.392+0000] {processor.py:186} INFO - Started process (PID=145) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T09:59:51.393+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T09:59:51.395+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:59:51.395+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T09:59:51.800+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T09:59:51.822+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:59:51.822+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T09:59:51.847+0000] {logging_mixin.py:190} INFO - [2025-01-13T09:59:51.847+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T09:59:51.869+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.483 seconds
[2025-01-13T10:00:22.098+0000] {processor.py:186} INFO - Started process (PID=152) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T10:00:22.099+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T10:00:22.101+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:00:22.100+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:00:22.577+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:00:22.598+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:00:22.598+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T10:00:22.620+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:00:22.620+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T10:00:22.643+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.551 seconds
[2025-01-13T10:00:52.781+0000] {processor.py:186} INFO - Started process (PID=159) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T10:00:52.782+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T10:00:52.786+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:00:52.785+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:00:53.336+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:00:53.356+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:00:53.355+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T10:00:53.377+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:00:53.377+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T10:00:53.393+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.621 seconds
[2025-01-13T10:01:23.612+0000] {processor.py:186} INFO - Started process (PID=166) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T10:01:23.613+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T10:01:23.616+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:01:23.616+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:01:24.077+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:01:24.100+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:01:24.099+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T10:01:24.125+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:01:24.124+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T10:01:24.151+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.546 seconds
[2025-01-13T10:01:54.207+0000] {processor.py:186} INFO - Started process (PID=173) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T10:01:54.208+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T10:01:54.210+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:01:54.210+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:01:54.620+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:01:54.639+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:01:54.638+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T10:01:54.656+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:01:54.656+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T10:01:54.693+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.492 seconds
[2025-01-13T10:02:24.943+0000] {processor.py:186} INFO - Started process (PID=179) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T10:02:24.944+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T10:02:24.946+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:02:24.946+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:02:25.342+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:02:25.362+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:02:25.362+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T10:02:25.380+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:02:25.380+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T10:02:25.398+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.460 seconds
[2025-01-13T10:02:55.659+0000] {processor.py:186} INFO - Started process (PID=185) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T10:02:55.660+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T10:02:55.663+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:02:55.663+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:02:56.151+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:02:56.171+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:02:56.171+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T10:02:56.195+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:02:56.194+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T10:02:56.213+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.561 seconds
[2025-01-13T10:03:26.384+0000] {processor.py:186} INFO - Started process (PID=192) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T10:03:26.385+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T10:03:26.388+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:03:26.387+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:03:26.909+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:03:26.941+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:03:26.941+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T10:03:26.991+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:03:26.989+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T10:03:27.027+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.649 seconds
[2025-01-13T10:03:57.361+0000] {processor.py:186} INFO - Started process (PID=200) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T10:03:57.362+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T10:03:57.364+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:03:57.364+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:03:58.044+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:03:58.109+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:03:58.108+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T10:03:58.154+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:03:58.154+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T10:03:58.194+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.840 seconds
[2025-01-13T10:04:28.437+0000] {processor.py:186} INFO - Started process (PID=207) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T10:04:28.439+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T10:04:28.442+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:04:28.441+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:04:28.901+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:04:28.922+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:04:28.921+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T10:04:28.944+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:04:28.943+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T10:04:28.964+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.534 seconds
[2025-01-13T10:04:59.112+0000] {processor.py:186} INFO - Started process (PID=214) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T10:04:59.113+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T10:04:59.115+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:04:59.115+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:04:59.651+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:04:59.670+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:04:59.669+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T10:04:59.693+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:04:59.692+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T10:04:59.715+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.609 seconds
[2025-01-13T10:05:29.911+0000] {processor.py:186} INFO - Started process (PID=221) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T10:05:29.912+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T10:05:29.915+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:05:29.914+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:05:30.491+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:05:30.514+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:05:30.514+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T10:05:30.540+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:05:30.540+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T10:05:30.564+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.661 seconds
[2025-01-13T10:06:00.793+0000] {processor.py:186} INFO - Started process (PID=228) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T10:06:00.794+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T10:06:00.796+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:06:00.795+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:06:01.281+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:06:01.303+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:06:01.302+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T10:06:01.323+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:06:01.323+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T10:06:01.344+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.559 seconds
[2025-01-13T10:06:12.482+0000] {processor.py:186} INFO - Started process (PID=229) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T10:06:12.483+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T10:06:12.486+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:06:12.485+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:06:13.063+0000] {logging_mixin.py:190} WARNING - /opt/airflow/dags/crawl_data.py:134 SyntaxWarning: invalid escape sequence '\T'
[2025-01-13T10:06:13.067+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:06:13.092+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:06:13.091+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T10:06:13.119+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:06:13.119+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T10:06:13.159+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.683 seconds
[2025-01-13T10:06:43.407+0000] {processor.py:186} INFO - Started process (PID=237) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T10:06:43.407+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T10:06:43.409+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:06:43.409+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:06:43.803+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:06:43.821+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:06:43.821+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T10:06:43.842+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:06:43.842+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T10:06:43.857+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.456 seconds
[2025-01-13T10:07:14.157+0000] {processor.py:186} INFO - Started process (PID=243) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T10:07:14.158+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T10:07:14.160+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:07:14.160+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:07:14.588+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:07:14.608+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:07:14.607+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T10:07:14.625+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:07:14.625+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T10:07:14.645+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.494 seconds
[2025-01-13T10:07:45.083+0000] {processor.py:186} INFO - Started process (PID=249) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T10:07:45.084+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T10:07:45.092+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:07:45.092+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:07:45.378+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:07:45.401+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:07:45.401+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T10:07:45.422+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:07:45.422+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T10:07:45.441+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.364 seconds
[2025-01-13T10:08:15.648+0000] {processor.py:186} INFO - Started process (PID=256) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T10:08:15.649+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T10:08:15.651+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:08:15.651+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:08:15.968+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:08:15.992+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:08:15.991+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T10:08:16.016+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:08:16.015+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T10:08:16.037+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.395 seconds
[2025-01-13T10:08:46.266+0000] {processor.py:186} INFO - Started process (PID=263) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T10:08:46.267+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T10:08:46.269+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:08:46.269+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:08:46.547+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:08:46.569+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:08:46.568+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T10:08:46.589+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:08:46.589+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T10:08:46.607+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.347 seconds
[2025-01-13T10:09:16.880+0000] {processor.py:186} INFO - Started process (PID=270) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T10:09:16.881+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T10:09:16.885+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:09:16.884+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:09:17.206+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:09:17.230+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:09:17.230+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T10:09:17.253+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:09:17.253+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T10:09:17.271+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.399 seconds
[2025-01-13T10:09:47.556+0000] {processor.py:186} INFO - Started process (PID=278) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T10:09:47.557+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T10:09:47.559+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:09:47.559+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:09:47.833+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:09:47.857+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:09:47.857+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T10:09:47.879+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:09:47.879+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T10:09:47.896+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.346 seconds
[2025-01-13T10:10:18.149+0000] {processor.py:186} INFO - Started process (PID=286) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T10:10:18.150+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T10:10:18.153+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:10:18.152+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:10:18.434+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:10:18.458+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:10:18.457+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T10:10:18.480+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:10:18.479+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T10:10:18.501+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.359 seconds
[2025-01-13T10:10:48.763+0000] {processor.py:186} INFO - Started process (PID=292) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T10:10:48.764+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T10:10:48.766+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:10:48.766+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:10:49.119+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:10:49.145+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:10:49.144+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T10:10:49.168+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:10:49.168+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T10:10:49.188+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.431 seconds
[2025-01-13T10:11:19.451+0000] {processor.py:186} INFO - Started process (PID=299) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T10:11:19.452+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T10:11:19.455+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:11:19.454+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:11:19.765+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:11:19.790+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:11:19.789+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T10:11:19.814+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:11:19.814+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T10:11:19.837+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.392 seconds
[2025-01-13T10:11:50.053+0000] {processor.py:186} INFO - Started process (PID=306) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T10:11:50.054+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T10:11:50.056+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:11:50.056+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:11:50.359+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:11:50.382+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:11:50.382+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T10:11:50.406+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:11:50.405+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T10:11:50.423+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.376 seconds
[2025-01-13T10:12:20.657+0000] {processor.py:186} INFO - Started process (PID=313) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T10:12:20.658+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T10:12:20.660+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:12:20.660+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:12:20.997+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:12:21.026+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:12:21.026+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T10:12:21.073+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:12:21.073+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T10:12:21.109+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.460 seconds
[2025-01-13T10:12:51.387+0000] {processor.py:186} INFO - Started process (PID=326) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T10:12:51.388+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T10:12:51.404+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:12:51.404+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:12:51.938+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:12:51.963+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:12:51.963+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T10:12:51.992+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:12:51.992+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T10:12:52.019+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.641 seconds
[2025-01-13T10:13:22.138+0000] {processor.py:186} INFO - Started process (PID=334) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T10:13:22.139+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T10:13:22.142+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:13:22.142+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:13:22.473+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:13:22.495+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:13:22.495+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T10:13:22.530+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:13:22.530+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T10:13:22.553+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.421 seconds
[2025-01-13T10:13:52.780+0000] {processor.py:186} INFO - Started process (PID=341) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T10:13:52.781+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T10:13:52.784+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:13:52.783+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:13:53.071+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:13:53.098+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:13:53.097+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T10:13:53.123+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:13:53.123+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T10:13:53.139+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.365 seconds
[2025-01-13T10:14:23.381+0000] {processor.py:186} INFO - Started process (PID=348) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T10:14:23.382+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T10:14:23.386+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:14:23.385+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:14:23.764+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:14:23.788+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:14:23.788+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T10:14:23.811+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:14:23.811+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T10:14:23.832+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.459 seconds
[2025-01-13T10:14:54.076+0000] {processor.py:186} INFO - Started process (PID=355) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T10:14:54.077+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T10:14:54.080+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:14:54.080+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:14:54.405+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:14:54.437+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:14:54.436+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T10:14:54.467+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:14:54.467+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T10:14:54.490+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.421 seconds
[2025-01-13T10:15:24.696+0000] {processor.py:186} INFO - Started process (PID=362) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T10:15:24.697+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T10:15:24.700+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:15:24.699+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:15:25.030+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:15:25.053+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:15:25.053+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T10:15:25.077+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:15:25.077+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T10:15:25.101+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.411 seconds
[2025-01-13T10:15:55.360+0000] {processor.py:186} INFO - Started process (PID=369) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T10:15:55.361+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T10:15:55.363+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:15:55.363+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:15:55.641+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:15:55.666+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:15:55.666+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T10:15:55.689+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:15:55.688+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T10:15:55.707+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.353 seconds
[2025-01-13T10:16:25.918+0000] {processor.py:186} INFO - Started process (PID=376) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T10:16:25.919+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T10:16:25.923+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:16:25.922+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:16:26.324+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:16:26.350+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:16:26.349+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T10:16:26.376+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:16:26.376+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T10:16:26.396+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.489 seconds
[2025-01-13T10:16:56.610+0000] {processor.py:186} INFO - Started process (PID=383) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T10:16:56.611+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T10:16:56.614+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:16:56.613+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:16:56.928+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:16:56.952+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:16:56.952+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T10:16:56.973+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:16:56.973+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T10:16:56.992+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.387 seconds
[2025-01-13T10:17:27.230+0000] {processor.py:186} INFO - Started process (PID=390) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T10:17:27.231+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T10:17:27.234+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:17:27.234+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:17:27.536+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:17:27.561+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:17:27.561+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T10:17:27.585+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:17:27.585+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T10:17:27.611+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.387 seconds
[2025-01-13T10:17:57.831+0000] {processor.py:186} INFO - Started process (PID=397) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T10:17:57.832+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T10:17:57.834+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:17:57.834+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:17:58.117+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:17:58.141+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:17:58.140+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T10:17:58.161+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:17:58.161+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T10:17:58.184+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.359 seconds
[2025-01-13T10:18:28.438+0000] {processor.py:186} INFO - Started process (PID=404) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T10:18:28.439+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T10:18:28.442+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:18:28.442+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:18:28.820+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:18:28.846+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:18:28.846+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T10:18:28.871+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:18:28.870+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T10:18:28.890+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.458 seconds
[2025-01-13T10:18:59.159+0000] {processor.py:186} INFO - Started process (PID=410) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T10:18:59.160+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T10:18:59.163+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:18:59.163+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:18:59.612+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:18:59.660+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:18:59.660+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T10:18:59.707+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:18:59.707+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T10:18:59.741+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.591 seconds
[2025-01-13T10:19:29.951+0000] {processor.py:186} INFO - Started process (PID=417) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T10:19:29.951+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T10:19:29.954+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:19:29.953+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:19:30.226+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:19:30.246+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:19:30.246+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T10:19:30.267+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:19:30.267+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T10:19:30.285+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.341 seconds
[2025-01-13T10:20:00.501+0000] {processor.py:186} INFO - Started process (PID=424) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T10:20:00.501+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T10:20:00.504+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:20:00.504+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:20:00.798+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T10:20:00.840+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:20:00.839+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T10:20:00.864+0000] {logging_mixin.py:190} INFO - [2025-01-13T10:20:00.864+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T10:20:00.884+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.389 seconds
[2025-01-13T12:25:30.018+0000] {processor.py:186} INFO - Started process (PID=64) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:25:30.021+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:25:30.024+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:25:30.023+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:25:31.695+0000] {logging_mixin.py:190} INFO - MYSQL_HOST: None
[2025-01-13T12:25:31.705+0000] {logging_mixin.py:190} INFO - MYSQL_USER: None
[2025-01-13T12:25:31.705+0000] {logging_mixin.py:190} INFO - MYSQL_PASSWORD: None
[2025-01-13T12:25:31.706+0000] {logging_mixin.py:190} INFO - MYSQL_DATABASE: None
[2025-01-13T12:25:31.706+0000] {logging_mixin.py:190} INFO - MYSQL_PORT: None
[2025-01-13T12:25:31.738+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:25:31.809+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:25:31.807+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:25:31.846+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:25:31.846+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:25:31.885+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 1.886 seconds
[2025-01-13T12:26:02.149+0000] {processor.py:186} INFO - Started process (PID=70) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:26:02.150+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:26:02.154+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:26:02.154+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:26:02.701+0000] {logging_mixin.py:190} INFO - MYSQL_HOST: None
[2025-01-13T12:26:02.702+0000] {logging_mixin.py:190} INFO - MYSQL_USER: None
[2025-01-13T12:26:02.702+0000] {logging_mixin.py:190} INFO - MYSQL_PASSWORD: None
[2025-01-13T12:26:02.703+0000] {logging_mixin.py:190} INFO - MYSQL_DATABASE: None
[2025-01-13T12:26:02.703+0000] {logging_mixin.py:190} INFO - MYSQL_PORT: None
[2025-01-13T12:26:02.711+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:26:02.731+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:26:02.730+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:26:02.753+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:26:02.753+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:26:02.774+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.632 seconds
[2025-01-13T12:26:32.999+0000] {processor.py:186} INFO - Started process (PID=77) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:26:33.000+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:26:33.002+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:26:33.001+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:26:33.420+0000] {logging_mixin.py:190} INFO - MYSQL_HOST: None
[2025-01-13T12:26:33.420+0000] {logging_mixin.py:190} INFO - MYSQL_USER: None
[2025-01-13T12:26:33.421+0000] {logging_mixin.py:190} INFO - MYSQL_PASSWORD: None
[2025-01-13T12:26:33.421+0000] {logging_mixin.py:190} INFO - MYSQL_DATABASE: None
[2025-01-13T12:26:33.422+0000] {logging_mixin.py:190} INFO - MYSQL_PORT: None
[2025-01-13T12:26:33.427+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:26:33.446+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:26:33.446+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:26:33.464+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:26:33.464+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:26:33.486+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.492 seconds
[2025-01-13T12:27:03.782+0000] {processor.py:186} INFO - Started process (PID=84) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:27:03.783+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:27:03.788+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:27:03.787+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:27:04.231+0000] {logging_mixin.py:190} INFO - MYSQL_HOST: None
[2025-01-13T12:27:04.232+0000] {logging_mixin.py:190} INFO - MYSQL_USER: None
[2025-01-13T12:27:04.232+0000] {logging_mixin.py:190} INFO - MYSQL_PASSWORD: None
[2025-01-13T12:27:04.233+0000] {logging_mixin.py:190} INFO - MYSQL_DATABASE: None
[2025-01-13T12:27:04.233+0000] {logging_mixin.py:190} INFO - MYSQL_PORT: None
[2025-01-13T12:27:04.239+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:27:04.256+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:27:04.256+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:27:04.275+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:27:04.274+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:27:04.296+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.527 seconds
[2025-01-13T12:27:34.569+0000] {processor.py:186} INFO - Started process (PID=90) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:27:34.571+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:27:34.574+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:27:34.573+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:27:34.949+0000] {logging_mixin.py:190} INFO - MYSQL_HOST: None
[2025-01-13T12:27:34.949+0000] {logging_mixin.py:190} INFO - MYSQL_USER: None
[2025-01-13T12:27:34.950+0000] {logging_mixin.py:190} INFO - MYSQL_PASSWORD: None
[2025-01-13T12:27:34.950+0000] {logging_mixin.py:190} INFO - MYSQL_DATABASE: None
[2025-01-13T12:27:34.951+0000] {logging_mixin.py:190} INFO - MYSQL_PORT: None
[2025-01-13T12:27:34.956+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:27:34.974+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:27:34.974+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:27:34.993+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:27:34.993+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:27:35.014+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.451 seconds
[2025-01-13T12:28:05.213+0000] {processor.py:186} INFO - Started process (PID=96) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:28:05.215+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:28:05.217+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:28:05.217+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:28:05.790+0000] {logging_mixin.py:190} INFO - MYSQL_HOST: None
[2025-01-13T12:28:05.790+0000] {logging_mixin.py:190} INFO - MYSQL_USER: None
[2025-01-13T12:28:05.791+0000] {logging_mixin.py:190} INFO - MYSQL_PASSWORD: None
[2025-01-13T12:28:05.791+0000] {logging_mixin.py:190} INFO - MYSQL_DATABASE: None
[2025-01-13T12:28:05.792+0000] {logging_mixin.py:190} INFO - MYSQL_PORT: None
[2025-01-13T12:28:05.797+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:28:05.815+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:28:05.815+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:28:05.834+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:28:05.834+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:28:05.848+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.641 seconds
[2025-01-13T12:28:36.142+0000] {processor.py:186} INFO - Started process (PID=103) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:28:36.144+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:28:36.146+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:28:36.146+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:28:36.644+0000] {logging_mixin.py:190} INFO - MYSQL_HOST: None
[2025-01-13T12:28:36.645+0000] {logging_mixin.py:190} INFO - MYSQL_USER: None
[2025-01-13T12:28:36.645+0000] {logging_mixin.py:190} INFO - MYSQL_PASSWORD: None
[2025-01-13T12:28:36.646+0000] {logging_mixin.py:190} INFO - MYSQL_DATABASE: None
[2025-01-13T12:28:36.646+0000] {logging_mixin.py:190} INFO - MYSQL_PORT: None
[2025-01-13T12:28:36.652+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:28:36.670+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:28:36.670+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:28:36.689+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:28:36.689+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:28:36.704+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.568 seconds
[2025-01-13T12:29:06.785+0000] {processor.py:186} INFO - Started process (PID=110) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:29:06.786+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:29:06.789+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:29:06.789+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:29:07.688+0000] {logging_mixin.py:190} INFO - MYSQL_HOST: None
[2025-01-13T12:29:07.696+0000] {logging_mixin.py:190} INFO - MYSQL_USER: None
[2025-01-13T12:29:07.697+0000] {logging_mixin.py:190} INFO - MYSQL_PASSWORD: None
[2025-01-13T12:29:07.697+0000] {logging_mixin.py:190} INFO - MYSQL_DATABASE: None
[2025-01-13T12:29:07.697+0000] {logging_mixin.py:190} INFO - MYSQL_PORT: None
[2025-01-13T12:29:07.717+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:29:07.780+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:29:07.780+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:29:07.815+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:29:07.815+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:29:07.851+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 1.091 seconds
[2025-01-13T12:29:38.043+0000] {processor.py:186} INFO - Started process (PID=117) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:29:38.044+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:29:38.046+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:29:38.046+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:29:38.427+0000] {logging_mixin.py:190} INFO - MYSQL_HOST: None
[2025-01-13T12:29:38.428+0000] {logging_mixin.py:190} INFO - MYSQL_USER: None
[2025-01-13T12:29:38.428+0000] {logging_mixin.py:190} INFO - MYSQL_PASSWORD: None
[2025-01-13T12:29:38.429+0000] {logging_mixin.py:190} INFO - MYSQL_DATABASE: None
[2025-01-13T12:29:38.429+0000] {logging_mixin.py:190} INFO - MYSQL_PORT: None
[2025-01-13T12:29:38.435+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:29:38.455+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:29:38.455+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:29:38.475+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:29:38.475+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:29:38.490+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.454 seconds
[2025-01-13T12:30:08.778+0000] {processor.py:186} INFO - Started process (PID=124) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:30:08.779+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:30:08.781+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:30:08.781+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:30:09.176+0000] {logging_mixin.py:190} INFO - MYSQL_HOST: None
[2025-01-13T12:30:09.177+0000] {logging_mixin.py:190} INFO - MYSQL_USER: None
[2025-01-13T12:30:09.178+0000] {logging_mixin.py:190} INFO - MYSQL_PASSWORD: None
[2025-01-13T12:30:09.178+0000] {logging_mixin.py:190} INFO - MYSQL_DATABASE: None
[2025-01-13T12:30:09.179+0000] {logging_mixin.py:190} INFO - MYSQL_PORT: None
[2025-01-13T12:30:09.184+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:30:09.203+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:30:09.202+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:30:09.222+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:30:09.222+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:30:09.239+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.466 seconds
[2025-01-13T12:30:39.490+0000] {processor.py:186} INFO - Started process (PID=131) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:30:39.491+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:30:39.498+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:30:39.498+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:30:39.942+0000] {logging_mixin.py:190} INFO - MYSQL_HOST: None
[2025-01-13T12:30:39.943+0000] {logging_mixin.py:190} INFO - MYSQL_USER: None
[2025-01-13T12:30:39.943+0000] {logging_mixin.py:190} INFO - MYSQL_PASSWORD: None
[2025-01-13T12:30:39.944+0000] {logging_mixin.py:190} INFO - MYSQL_DATABASE: None
[2025-01-13T12:30:39.944+0000] {logging_mixin.py:190} INFO - MYSQL_PORT: None
[2025-01-13T12:30:39.951+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:30:39.969+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:30:39.969+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:30:39.988+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:30:39.988+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:30:40.005+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.521 seconds
[2025-01-13T12:31:10.341+0000] {processor.py:186} INFO - Started process (PID=138) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:31:10.342+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:31:10.344+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:31:10.344+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:31:10.712+0000] {logging_mixin.py:190} INFO - MYSQL_HOST: None
[2025-01-13T12:31:10.713+0000] {logging_mixin.py:190} INFO - MYSQL_USER: None
[2025-01-13T12:31:10.714+0000] {logging_mixin.py:190} INFO - MYSQL_PASSWORD: None
[2025-01-13T12:31:10.714+0000] {logging_mixin.py:190} INFO - MYSQL_DATABASE: None
[2025-01-13T12:31:10.714+0000] {logging_mixin.py:190} INFO - MYSQL_PORT: None
[2025-01-13T12:31:10.721+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:31:10.740+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:31:10.739+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:31:10.758+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:31:10.757+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:31:10.784+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.448 seconds
[2025-01-13T12:31:41.011+0000] {processor.py:186} INFO - Started process (PID=145) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:31:41.012+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:31:41.014+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:31:41.014+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:31:41.400+0000] {logging_mixin.py:190} INFO - MYSQL_HOST: None
[2025-01-13T12:31:41.401+0000] {logging_mixin.py:190} INFO - MYSQL_USER: None
[2025-01-13T12:31:41.402+0000] {logging_mixin.py:190} INFO - MYSQL_PASSWORD: None
[2025-01-13T12:31:41.402+0000] {logging_mixin.py:190} INFO - MYSQL_DATABASE: None
[2025-01-13T12:31:41.402+0000] {logging_mixin.py:190} INFO - MYSQL_PORT: None
[2025-01-13T12:31:41.408+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:31:41.426+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:31:41.426+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:31:41.444+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:31:41.443+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:31:41.466+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.461 seconds
[2025-01-13T12:32:11.760+0000] {processor.py:186} INFO - Started process (PID=153) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:32:11.761+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:32:11.763+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:32:11.762+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:32:12.140+0000] {logging_mixin.py:190} INFO - MYSQL_HOST: None
[2025-01-13T12:32:12.141+0000] {logging_mixin.py:190} INFO - MYSQL_USER: None
[2025-01-13T12:32:12.141+0000] {logging_mixin.py:190} INFO - MYSQL_PASSWORD: None
[2025-01-13T12:32:12.142+0000] {logging_mixin.py:190} INFO - MYSQL_DATABASE: None
[2025-01-13T12:32:12.142+0000] {logging_mixin.py:190} INFO - MYSQL_PORT: None
[2025-01-13T12:32:12.148+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:32:12.165+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:32:12.165+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:32:12.184+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:32:12.184+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:32:12.204+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.449 seconds
[2025-01-13T12:32:42.525+0000] {processor.py:186} INFO - Started process (PID=160) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:32:42.526+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:32:42.528+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:32:42.528+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:32:42.892+0000] {logging_mixin.py:190} INFO - MYSQL_HOST: None
[2025-01-13T12:32:42.893+0000] {logging_mixin.py:190} INFO - MYSQL_USER: None
[2025-01-13T12:32:42.894+0000] {logging_mixin.py:190} INFO - MYSQL_PASSWORD: None
[2025-01-13T12:32:42.894+0000] {logging_mixin.py:190} INFO - MYSQL_DATABASE: None
[2025-01-13T12:32:42.894+0000] {logging_mixin.py:190} INFO - MYSQL_PORT: None
[2025-01-13T12:32:42.901+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:32:42.922+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:32:42.922+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:32:42.942+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:32:42.942+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:32:42.963+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.444 seconds
[2025-01-13T12:33:13.256+0000] {processor.py:186} INFO - Started process (PID=167) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:33:13.257+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:33:13.259+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:33:13.258+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:33:13.638+0000] {logging_mixin.py:190} INFO - MYSQL_HOST: None
[2025-01-13T12:33:13.639+0000] {logging_mixin.py:190} INFO - MYSQL_USER: None
[2025-01-13T12:33:13.639+0000] {logging_mixin.py:190} INFO - MYSQL_PASSWORD: None
[2025-01-13T12:33:13.640+0000] {logging_mixin.py:190} INFO - MYSQL_DATABASE: None
[2025-01-13T12:33:13.640+0000] {logging_mixin.py:190} INFO - MYSQL_PORT: None
[2025-01-13T12:33:13.646+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:33:13.664+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:33:13.663+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:33:13.681+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:33:13.681+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:33:13.695+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.446 seconds
[2025-01-13T12:33:43.999+0000] {processor.py:186} INFO - Started process (PID=174) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:33:44.000+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:33:44.002+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:33:44.002+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:33:44.380+0000] {logging_mixin.py:190} INFO - MYSQL_HOST: None
[2025-01-13T12:33:44.380+0000] {logging_mixin.py:190} INFO - MYSQL_USER: None
[2025-01-13T12:33:44.381+0000] {logging_mixin.py:190} INFO - MYSQL_PASSWORD: None
[2025-01-13T12:33:44.381+0000] {logging_mixin.py:190} INFO - MYSQL_DATABASE: None
[2025-01-13T12:33:44.381+0000] {logging_mixin.py:190} INFO - MYSQL_PORT: None
[2025-01-13T12:33:44.387+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:33:44.404+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:33:44.404+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:33:44.424+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:33:44.423+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:33:44.441+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.448 seconds
[2025-01-13T12:34:14.746+0000] {processor.py:186} INFO - Started process (PID=181) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:34:14.747+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:34:14.749+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:34:14.749+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:34:15.153+0000] {logging_mixin.py:190} INFO - MYSQL_HOST: None
[2025-01-13T12:34:15.154+0000] {logging_mixin.py:190} INFO - MYSQL_USER: None
[2025-01-13T12:34:15.154+0000] {logging_mixin.py:190} INFO - MYSQL_PASSWORD: None
[2025-01-13T12:34:15.155+0000] {logging_mixin.py:190} INFO - MYSQL_DATABASE: None
[2025-01-13T12:34:15.155+0000] {logging_mixin.py:190} INFO - MYSQL_PORT: None
[2025-01-13T12:34:15.161+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:34:15.184+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:34:15.184+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:34:15.209+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:34:15.208+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:34:15.235+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.494 seconds
[2025-01-13T12:34:45.508+0000] {processor.py:186} INFO - Started process (PID=189) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:34:45.509+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:34:45.512+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:34:45.511+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:34:45.922+0000] {logging_mixin.py:190} INFO - MYSQL_HOST: None
[2025-01-13T12:34:45.922+0000] {logging_mixin.py:190} INFO - MYSQL_USER: None
[2025-01-13T12:34:45.923+0000] {logging_mixin.py:190} INFO - MYSQL_PASSWORD: None
[2025-01-13T12:34:45.923+0000] {logging_mixin.py:190} INFO - MYSQL_DATABASE: None
[2025-01-13T12:34:45.924+0000] {logging_mixin.py:190} INFO - MYSQL_PORT: None
[2025-01-13T12:34:45.930+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:34:45.948+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:34:45.947+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:34:45.967+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:34:45.967+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:34:45.988+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.486 seconds
[2025-01-13T12:35:16.224+0000] {processor.py:186} INFO - Started process (PID=196) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:35:16.231+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:35:16.233+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:35:16.233+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:35:16.824+0000] {logging_mixin.py:190} INFO - MYSQL_HOST: None
[2025-01-13T12:35:16.825+0000] {logging_mixin.py:190} INFO - MYSQL_USER: None
[2025-01-13T12:35:16.825+0000] {logging_mixin.py:190} INFO - MYSQL_PASSWORD: None
[2025-01-13T12:35:16.826+0000] {logging_mixin.py:190} INFO - MYSQL_DATABASE: None
[2025-01-13T12:35:16.826+0000] {logging_mixin.py:190} INFO - MYSQL_PORT: None
[2025-01-13T12:35:16.833+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:35:16.856+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:35:16.855+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:35:16.879+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:35:16.879+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:35:16.902+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.692 seconds
[2025-01-13T12:35:47.008+0000] {processor.py:186} INFO - Started process (PID=209) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:35:47.009+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:35:47.011+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:35:47.011+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:35:47.422+0000] {logging_mixin.py:190} INFO - MYSQL_HOST: None
[2025-01-13T12:35:47.423+0000] {logging_mixin.py:190} INFO - MYSQL_USER: None
[2025-01-13T12:35:47.424+0000] {logging_mixin.py:190} INFO - MYSQL_PASSWORD: None
[2025-01-13T12:35:47.424+0000] {logging_mixin.py:190} INFO - MYSQL_DATABASE: None
[2025-01-13T12:35:47.425+0000] {logging_mixin.py:190} INFO - MYSQL_PORT: None
[2025-01-13T12:35:47.432+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:35:47.452+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:35:47.452+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:35:47.471+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:35:47.470+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:35:47.487+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.485 seconds
[2025-01-13T12:36:17.780+0000] {processor.py:186} INFO - Started process (PID=216) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:36:17.782+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:36:17.784+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:36:17.784+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:36:18.303+0000] {logging_mixin.py:190} INFO - MYSQL_HOST: None
[2025-01-13T12:36:18.304+0000] {logging_mixin.py:190} INFO - MYSQL_USER: None
[2025-01-13T12:36:18.304+0000] {logging_mixin.py:190} INFO - MYSQL_PASSWORD: None
[2025-01-13T12:36:18.305+0000] {logging_mixin.py:190} INFO - MYSQL_DATABASE: None
[2025-01-13T12:36:18.305+0000] {logging_mixin.py:190} INFO - MYSQL_PORT: None
[2025-01-13T12:36:18.313+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:36:18.341+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:36:18.341+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:36:18.368+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:36:18.368+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:36:18.388+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.615 seconds
[2025-01-13T12:36:48.691+0000] {processor.py:186} INFO - Started process (PID=223) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:36:48.692+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:36:48.694+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:36:48.694+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:36:49.052+0000] {logging_mixin.py:190} INFO - MYSQL_HOST: None
[2025-01-13T12:36:49.053+0000] {logging_mixin.py:190} INFO - MYSQL_USER: None
[2025-01-13T12:36:49.054+0000] {logging_mixin.py:190} INFO - MYSQL_PASSWORD: None
[2025-01-13T12:36:49.054+0000] {logging_mixin.py:190} INFO - MYSQL_DATABASE: None
[2025-01-13T12:36:49.055+0000] {logging_mixin.py:190} INFO - MYSQL_PORT: None
[2025-01-13T12:36:49.060+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:36:49.078+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:36:49.078+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:36:49.097+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:36:49.097+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:36:49.117+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.431 seconds
[2025-01-13T12:37:19.275+0000] {processor.py:186} INFO - Started process (PID=230) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:37:19.276+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:37:19.279+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:37:19.278+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:37:19.751+0000] {logging_mixin.py:190} INFO - MYSQL_HOST: None
[2025-01-13T12:37:19.752+0000] {logging_mixin.py:190} INFO - MYSQL_USER: None
[2025-01-13T12:37:19.752+0000] {logging_mixin.py:190} INFO - MYSQL_PASSWORD: None
[2025-01-13T12:37:19.752+0000] {logging_mixin.py:190} INFO - MYSQL_DATABASE: None
[2025-01-13T12:37:19.753+0000] {logging_mixin.py:190} INFO - MYSQL_PORT: None
[2025-01-13T12:37:19.759+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:37:19.781+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:37:19.780+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:37:19.800+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:37:19.800+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:37:19.815+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.547 seconds
[2025-01-13T12:37:50.043+0000] {processor.py:186} INFO - Started process (PID=237) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:37:50.044+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:37:50.046+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:37:50.046+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:37:50.504+0000] {logging_mixin.py:190} INFO - MYSQL_HOST: None
[2025-01-13T12:37:50.505+0000] {logging_mixin.py:190} INFO - MYSQL_USER: None
[2025-01-13T12:37:50.506+0000] {logging_mixin.py:190} INFO - MYSQL_PASSWORD: None
[2025-01-13T12:37:50.507+0000] {logging_mixin.py:190} INFO - MYSQL_DATABASE: None
[2025-01-13T12:37:50.507+0000] {logging_mixin.py:190} INFO - MYSQL_PORT: None
[2025-01-13T12:37:50.518+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:37:50.562+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:37:50.561+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:37:50.589+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:37:50.589+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:37:50.619+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.583 seconds
[2025-01-13T12:38:20.937+0000] {processor.py:186} INFO - Started process (PID=245) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:38:20.938+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:38:20.941+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:38:20.940+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:38:21.304+0000] {logging_mixin.py:190} INFO - MYSQL_HOST: None
[2025-01-13T12:38:21.304+0000] {logging_mixin.py:190} INFO - MYSQL_USER: None
[2025-01-13T12:38:21.305+0000] {logging_mixin.py:190} INFO - MYSQL_PASSWORD: None
[2025-01-13T12:38:21.305+0000] {logging_mixin.py:190} INFO - MYSQL_DATABASE: None
[2025-01-13T12:38:21.306+0000] {logging_mixin.py:190} INFO - MYSQL_PORT: None
[2025-01-13T12:38:21.311+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:38:21.330+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:38:21.329+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:38:21.350+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:38:21.350+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:38:21.364+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.436 seconds
[2025-01-13T12:38:51.500+0000] {processor.py:186} INFO - Started process (PID=252) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:38:51.501+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:38:51.503+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:38:51.503+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:38:51.900+0000] {logging_mixin.py:190} INFO - MYSQL_HOST: None
[2025-01-13T12:38:51.901+0000] {logging_mixin.py:190} INFO - MYSQL_USER: None
[2025-01-13T12:38:51.901+0000] {logging_mixin.py:190} INFO - MYSQL_PASSWORD: None
[2025-01-13T12:38:51.902+0000] {logging_mixin.py:190} INFO - MYSQL_DATABASE: None
[2025-01-13T12:38:51.902+0000] {logging_mixin.py:190} INFO - MYSQL_PORT: None
[2025-01-13T12:38:51.909+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:38:51.927+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:38:51.927+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:38:51.946+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:38:51.945+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:38:51.975+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.481 seconds
[2025-01-13T12:39:22.305+0000] {processor.py:186} INFO - Started process (PID=260) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:39:22.306+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:39:22.308+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:39:22.308+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:39:22.691+0000] {logging_mixin.py:190} INFO - MYSQL_HOST: None
[2025-01-13T12:39:22.691+0000] {logging_mixin.py:190} INFO - MYSQL_USER: None
[2025-01-13T12:39:22.692+0000] {logging_mixin.py:190} INFO - MYSQL_PASSWORD: None
[2025-01-13T12:39:22.692+0000] {logging_mixin.py:190} INFO - MYSQL_DATABASE: None
[2025-01-13T12:39:22.693+0000] {logging_mixin.py:190} INFO - MYSQL_PORT: None
[2025-01-13T12:39:22.699+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:39:22.717+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:39:22.717+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:39:22.734+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:39:22.734+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:39:22.748+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.449 seconds
[2025-01-13T12:39:53.019+0000] {processor.py:186} INFO - Started process (PID=268) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:39:53.019+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:39:53.022+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:39:53.021+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:39:53.383+0000] {logging_mixin.py:190} INFO - MYSQL_HOST: None
[2025-01-13T12:39:53.384+0000] {logging_mixin.py:190} INFO - MYSQL_USER: None
[2025-01-13T12:39:53.384+0000] {logging_mixin.py:190} INFO - MYSQL_PASSWORD: None
[2025-01-13T12:39:53.385+0000] {logging_mixin.py:190} INFO - MYSQL_DATABASE: None
[2025-01-13T12:39:53.385+0000] {logging_mixin.py:190} INFO - MYSQL_PORT: None
[2025-01-13T12:39:53.390+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:39:53.408+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:39:53.407+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:39:53.425+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:39:53.425+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:39:53.447+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.434 seconds
[2025-01-13T12:40:23.744+0000] {processor.py:186} INFO - Started process (PID=275) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:40:23.745+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:40:23.747+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:40:23.747+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:40:24.114+0000] {logging_mixin.py:190} INFO - MYSQL_HOST: None
[2025-01-13T12:40:24.115+0000] {logging_mixin.py:190} INFO - MYSQL_USER: None
[2025-01-13T12:40:24.115+0000] {logging_mixin.py:190} INFO - MYSQL_PASSWORD: None
[2025-01-13T12:40:24.115+0000] {logging_mixin.py:190} INFO - MYSQL_DATABASE: None
[2025-01-13T12:40:24.116+0000] {logging_mixin.py:190} INFO - MYSQL_PORT: None
[2025-01-13T12:40:24.122+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:40:24.140+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:40:24.140+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:40:24.161+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:40:24.160+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:40:24.177+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.438 seconds
[2025-01-13T12:46:15.653+0000] {processor.py:186} INFO - Started process (PID=60) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:46:15.654+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:46:15.661+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:46:15.661+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:46:17.167+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:46:17.234+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:46:17.233+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:46:17.290+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:46:17.289+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:46:17.329+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 1.691 seconds
[2025-01-13T12:46:47.554+0000] {processor.py:186} INFO - Started process (PID=67) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:46:47.555+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:46:47.558+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:46:47.558+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:46:48.039+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:46:48.070+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:46:48.070+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:46:48.095+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:46:48.094+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:46:48.115+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.570 seconds
[2025-01-13T12:47:18.382+0000] {processor.py:186} INFO - Started process (PID=75) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:47:18.383+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:47:18.385+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:47:18.385+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:47:18.756+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:47:18.776+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:47:18.776+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:47:18.795+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:47:18.794+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:47:18.815+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.438 seconds
[2025-01-13T12:47:49.075+0000] {processor.py:186} INFO - Started process (PID=82) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:47:49.076+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:47:49.078+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:47:49.078+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:47:49.547+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:47:49.582+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:47:49.581+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:47:49.600+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:47:49.600+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:47:49.618+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.548 seconds
[2025-01-13T12:48:19.900+0000] {processor.py:186} INFO - Started process (PID=88) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:48:19.900+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:48:19.902+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:48:19.902+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:48:20.281+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:48:20.298+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:48:20.298+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:48:20.316+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:48:20.316+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:48:20.336+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.442 seconds
[2025-01-13T12:48:41.362+0000] {processor.py:186} INFO - Started process (PID=104) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:48:41.363+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:48:41.365+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:48:41.365+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:48:42.052+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:48:42.079+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:48:42.078+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:48:42.099+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:48:42.099+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:48:42.115+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.759 seconds
[2025-01-13T12:48:50.624+0000] {processor.py:186} INFO - Started process (PID=95) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:48:50.626+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:48:50.630+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:48:50.630+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:48:51.080+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:48:51.103+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:48:51.102+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:48:51.129+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:48:51.129+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:48:51.148+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.533 seconds
[2025-01-13T12:49:12.399+0000] {processor.py:186} INFO - Started process (PID=111) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:49:12.400+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:49:12.403+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:49:12.402+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:49:12.830+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:49:12.849+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:49:12.849+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:49:12.870+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:49:12.870+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:49:12.885+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.493 seconds
[2025-01-13T12:49:21.450+0000] {processor.py:186} INFO - Started process (PID=102) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:49:21.451+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:49:21.453+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:49:21.452+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:49:21.856+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:49:21.880+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:49:21.879+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:49:21.905+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:49:21.905+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:49:21.919+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.474 seconds
[2025-01-13T12:49:43.144+0000] {processor.py:186} INFO - Started process (PID=118) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:49:43.145+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:49:43.148+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:49:43.148+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:49:43.541+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:49:43.562+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:49:43.561+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:49:43.583+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:49:43.583+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:49:43.608+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.469 seconds
[2025-01-13T12:49:52.194+0000] {processor.py:186} INFO - Started process (PID=110) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:49:52.195+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:49:52.197+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:49:52.197+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:49:52.657+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:49:52.681+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:49:52.680+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:49:52.702+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:49:52.702+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:49:52.727+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.539 seconds
[2025-01-13T12:50:13.894+0000] {processor.py:186} INFO - Started process (PID=125) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:50:13.896+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:50:13.898+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:50:13.898+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:50:14.307+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:50:14.339+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:50:14.339+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:50:14.367+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:50:14.366+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:50:14.384+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.496 seconds
[2025-01-13T12:50:23.107+0000] {processor.py:186} INFO - Started process (PID=117) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:50:23.108+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:50:23.111+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:50:23.111+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:50:24.133+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:50:24.172+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:50:24.172+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:50:24.244+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:50:24.242+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:50:24.377+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 1.279 seconds
[2025-01-13T12:50:44.892+0000] {processor.py:186} INFO - Started process (PID=132) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:50:44.893+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:50:44.896+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:50:44.895+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:50:45.286+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:50:45.308+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:50:45.308+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:50:45.330+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:50:45.330+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:50:45.345+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.462 seconds
[2025-01-13T12:50:54.743+0000] {processor.py:186} INFO - Started process (PID=124) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:50:54.745+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:50:54.747+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:50:54.746+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:50:55.133+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:50:55.151+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:50:55.151+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:50:55.170+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:50:55.170+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:50:55.184+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.446 seconds
[2025-01-13T12:51:15.607+0000] {processor.py:186} INFO - Started process (PID=139) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:51:15.608+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:51:15.610+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:51:15.610+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:51:15.995+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:51:16.018+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:51:16.018+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:51:16.054+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:51:16.054+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:51:16.079+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.477 seconds
[2025-01-13T12:51:25.433+0000] {processor.py:186} INFO - Started process (PID=132) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:51:25.434+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:51:25.437+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:51:25.437+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:51:25.823+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:51:25.842+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:51:25.841+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:51:25.861+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:51:25.860+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:51:25.881+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.454 seconds
[2025-01-13T12:51:46.390+0000] {processor.py:186} INFO - Started process (PID=146) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:51:46.391+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:51:46.393+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:51:46.393+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:51:46.857+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:51:46.878+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:51:46.877+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:51:46.899+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:51:46.899+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:51:46.915+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.531 seconds
[2025-01-13T12:51:56.239+0000] {processor.py:186} INFO - Started process (PID=139) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:51:56.240+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:51:56.243+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:51:56.243+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:51:56.652+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:51:56.671+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:51:56.671+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:51:56.690+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:51:56.689+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:51:56.705+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.472 seconds
[2025-01-13T12:52:17.180+0000] {processor.py:186} INFO - Started process (PID=153) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:52:17.181+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:52:17.183+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:52:17.182+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:52:17.574+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:52:17.593+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:52:17.593+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:52:17.615+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:52:17.615+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:52:17.637+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.463 seconds
[2025-01-13T12:52:26.985+0000] {processor.py:186} INFO - Started process (PID=146) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:52:26.986+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:52:26.988+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:52:26.988+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:52:27.378+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:52:27.397+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:52:27.397+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:52:27.417+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:52:27.417+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:52:27.434+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.454 seconds
[2025-01-13T12:52:48.067+0000] {processor.py:186} INFO - Started process (PID=160) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:52:48.068+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:52:48.070+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:52:48.070+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:52:48.350+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:52:48.375+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:52:48.374+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:52:48.398+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:52:48.398+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:52:48.416+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.354 seconds
[2025-01-13T12:52:57.685+0000] {processor.py:186} INFO - Started process (PID=153) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:52:57.685+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:52:57.687+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:52:57.687+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:52:58.078+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:52:58.097+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:52:58.097+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:52:58.117+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:52:58.117+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:52:58.132+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.454 seconds
[2025-01-13T12:53:18.663+0000] {processor.py:186} INFO - Started process (PID=167) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:53:18.664+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:53:18.666+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:53:18.665+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:53:18.961+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:53:18.989+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:53:18.988+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:53:19.015+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:53:19.015+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:53:19.033+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.376 seconds
[2025-01-13T12:53:28.452+0000] {processor.py:186} INFO - Started process (PID=160) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:53:28.453+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:53:28.455+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:53:28.455+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:53:28.835+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:53:28.853+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:53:28.853+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:53:28.873+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:53:28.872+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:53:28.888+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.442 seconds
[2025-01-13T12:53:49.347+0000] {processor.py:186} INFO - Started process (PID=174) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:53:49.348+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:53:49.350+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:53:49.350+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:53:49.632+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:53:49.655+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:53:49.654+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:53:49.678+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:53:49.678+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:53:49.696+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.355 seconds
[2025-01-13T12:53:59.196+0000] {processor.py:186} INFO - Started process (PID=168) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:53:59.197+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:53:59.199+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:53:59.199+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:53:59.676+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:53:59.694+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:53:59.693+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:53:59.712+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:53:59.712+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:53:59.727+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.536 seconds
[2025-01-13T12:54:20.013+0000] {processor.py:186} INFO - Started process (PID=181) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:54:20.014+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:54:20.018+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:54:20.017+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:54:20.418+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:54:20.447+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:54:20.446+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:54:20.479+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:54:20.479+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:54:20.499+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.500 seconds
[2025-01-13T12:54:29.990+0000] {processor.py:186} INFO - Started process (PID=181) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:54:29.991+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:54:29.995+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:54:29.994+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:54:30.416+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:54:30.436+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:54:30.435+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:54:30.455+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:54:30.455+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:54:30.470+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.490 seconds
[2025-01-13T12:54:50.790+0000] {processor.py:186} INFO - Started process (PID=189) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:54:50.791+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:54:50.794+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:54:50.793+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:54:51.110+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:54:51.136+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:54:51.135+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:54:51.173+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:54:51.173+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:54:51.193+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.408 seconds
[2025-01-13T12:55:00.789+0000] {processor.py:186} INFO - Started process (PID=188) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:55:00.790+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:55:00.792+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:55:00.792+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:55:01.170+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:55:01.188+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:55:01.187+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:55:01.207+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:55:01.207+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:55:01.227+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.444 seconds
[2025-01-13T12:55:21.517+0000] {processor.py:186} INFO - Started process (PID=196) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:55:21.518+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:55:21.529+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:55:21.529+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:55:21.937+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:55:21.964+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:55:21.963+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:55:21.989+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:55:21.989+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:55:22.008+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.497 seconds
[2025-01-13T12:55:31.564+0000] {processor.py:186} INFO - Started process (PID=195) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:55:31.565+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:55:31.567+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:55:31.567+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:55:31.933+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:55:31.951+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:55:31.950+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:55:31.969+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:55:31.969+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:55:31.984+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.425 seconds
[2025-01-13T12:55:52.349+0000] {processor.py:186} INFO - Started process (PID=203) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:55:52.350+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:55:52.352+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:55:52.352+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:55:52.613+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:55:52.635+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:55:52.634+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:55:52.655+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:55:52.655+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:55:52.680+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.337 seconds
[2025-01-13T12:56:02.265+0000] {processor.py:186} INFO - Started process (PID=202) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:56:02.266+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:56:02.268+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:56:02.268+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:56:02.640+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:56:02.674+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:56:02.673+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:56:02.693+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:56:02.692+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:56:02.710+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.449 seconds
[2025-01-13T12:56:22.940+0000] {processor.py:186} INFO - Started process (PID=210) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:56:22.941+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:56:22.944+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:56:22.943+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:56:23.287+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:56:23.315+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:56:23.315+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:56:23.343+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:56:23.343+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:56:23.363+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.430 seconds
[2025-01-13T12:56:32.982+0000] {processor.py:186} INFO - Started process (PID=209) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:56:32.984+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:56:32.986+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:56:32.986+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:56:33.447+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:56:33.466+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:56:33.465+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:56:33.486+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:56:33.486+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:56:33.502+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.526 seconds
[2025-01-13T12:56:53.644+0000] {processor.py:186} INFO - Started process (PID=216) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:56:53.645+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:56:53.647+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:56:53.646+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:56:53.901+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:56:53.923+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:56:53.923+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:56:53.952+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:56:53.952+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:56:53.969+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.331 seconds
[2025-01-13T12:57:03.852+0000] {processor.py:186} INFO - Started process (PID=217) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:57:03.852+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:57:03.855+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:57:03.854+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:57:04.265+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:57:04.287+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:57:04.286+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:57:04.308+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:57:04.308+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:57:04.322+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.476 seconds
[2025-01-13T12:57:24.270+0000] {processor.py:186} INFO - Started process (PID=222) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:57:24.271+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:57:24.273+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:57:24.272+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:57:24.529+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:57:24.553+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:57:24.553+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:57:24.574+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:57:24.574+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:57:24.591+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.327 seconds
[2025-01-13T12:57:34.600+0000] {processor.py:186} INFO - Started process (PID=224) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:57:34.601+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:57:34.603+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:57:34.602+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:57:34.967+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:57:34.985+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:57:34.984+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:57:35.002+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:57:35.002+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:57:35.017+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.423 seconds
[2025-01-13T12:57:54.898+0000] {processor.py:186} INFO - Started process (PID=230) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:57:54.899+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:57:54.902+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:57:54.902+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:57:55.170+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:57:55.196+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:57:55.195+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:57:55.218+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:57:55.218+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:57:55.235+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.343 seconds
[2025-01-13T12:58:05.340+0000] {processor.py:186} INFO - Started process (PID=231) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:58:05.341+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:58:05.344+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:58:05.344+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:58:05.950+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:58:05.971+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:58:05.970+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:58:05.993+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:58:05.993+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:58:06.009+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.675 seconds
[2025-01-13T12:58:25.479+0000] {processor.py:186} INFO - Started process (PID=237) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:58:25.480+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:58:25.482+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:58:25.482+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:58:25.796+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:58:25.823+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:58:25.822+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:58:25.850+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:58:25.849+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:58:25.877+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.403 seconds
[2025-01-13T12:58:36.163+0000] {processor.py:186} INFO - Started process (PID=238) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:58:36.164+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:58:36.167+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:58:36.166+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:58:36.678+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:58:36.701+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:58:36.700+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:58:36.723+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:58:36.723+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:58:36.740+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.584 seconds
[2025-01-13T12:58:56.135+0000] {processor.py:186} INFO - Started process (PID=244) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:58:56.136+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:58:56.139+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:58:56.139+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:58:56.485+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:58:56.517+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:58:56.517+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:58:56.557+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:58:56.556+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:58:56.589+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.462 seconds
[2025-01-13T12:59:06.996+0000] {processor.py:186} INFO - Started process (PID=245) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:59:06.997+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:59:06.999+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:59:06.999+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:59:07.463+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:59:07.484+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:59:07.483+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:59:07.506+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:59:07.506+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:59:07.523+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.533 seconds
[2025-01-13T12:59:26.879+0000] {processor.py:186} INFO - Started process (PID=251) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:59:26.880+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:59:26.883+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:59:26.883+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:59:27.154+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:59:27.178+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:59:27.178+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:59:27.202+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:59:27.202+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:59:27.219+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.346 seconds
[2025-01-13T12:59:37.767+0000] {processor.py:186} INFO - Started process (PID=252) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:59:37.767+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:59:37.770+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:59:37.769+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:59:38.175+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:59:38.195+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:59:38.195+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:59:38.217+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:59:38.216+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:59:38.233+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.472 seconds
[2025-01-13T12:59:57.476+0000] {processor.py:186} INFO - Started process (PID=258) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T12:59:57.477+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T12:59:57.479+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:59:57.479+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:59:57.817+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T12:59:57.857+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:59:57.856+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T12:59:57.883+0000] {logging_mixin.py:190} INFO - [2025-01-13T12:59:57.883+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T12:59:57.907+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.437 seconds
[2025-01-13T13:00:08.498+0000] {processor.py:186} INFO - Started process (PID=259) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:00:08.499+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:00:08.501+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:00:08.501+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:00:08.926+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:00:08.950+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:00:08.949+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:00:08.971+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:00:08.971+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:00:08.991+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.498 seconds
[2025-01-13T13:00:28.175+0000] {processor.py:186} INFO - Started process (PID=266) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:00:28.176+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:00:28.178+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:00:28.178+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:00:28.445+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:00:28.470+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:00:28.469+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:00:28.491+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:00:28.491+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:00:28.515+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.345 seconds
[2025-01-13T13:00:39.257+0000] {processor.py:186} INFO - Started process (PID=266) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:00:39.259+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:00:39.262+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:00:39.261+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:00:39.688+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:00:39.709+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:00:39.708+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:00:39.729+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:00:39.729+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:00:39.751+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.502 seconds
[2025-01-13T13:00:58.772+0000] {processor.py:186} INFO - Started process (PID=273) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:00:58.773+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:00:58.775+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:00:58.775+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:00:59.049+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:00:59.071+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:00:59.071+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:00:59.094+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:00:59.094+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:00:59.111+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.349 seconds
[2025-01-13T13:01:10.031+0000] {processor.py:186} INFO - Started process (PID=272) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:01:10.031+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:01:10.034+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:01:10.034+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:01:10.403+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:01:10.421+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:01:10.421+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:01:10.439+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:01:10.439+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:01:10.460+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.435 seconds
[2025-01-13T13:01:29.392+0000] {processor.py:186} INFO - Started process (PID=280) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:01:29.394+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:01:29.399+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:01:29.398+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:01:29.737+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:01:29.764+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:01:29.763+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:01:29.789+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:01:29.788+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:01:29.808+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.422 seconds
[2025-01-13T13:01:40.784+0000] {processor.py:186} INFO - Started process (PID=278) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:01:40.785+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:01:40.787+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:01:40.787+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:01:41.178+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:01:41.196+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:01:41.196+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:01:41.214+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:01:41.214+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:01:41.229+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.450 seconds
[2025-01-13T13:02:00.079+0000] {processor.py:186} INFO - Started process (PID=287) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:02:00.080+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:02:00.083+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:02:00.082+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:02:00.517+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:02:00.565+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:02:00.564+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:02:00.608+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:02:00.608+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:02:00.632+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.559 seconds
[2025-01-13T13:02:11.504+0000] {processor.py:186} INFO - Started process (PID=285) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:02:11.505+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:02:11.508+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:02:11.508+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:02:12.159+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:02:12.190+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:02:12.189+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:02:12.227+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:02:12.226+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:02:12.255+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.758 seconds
[2025-01-13T13:02:30.859+0000] {processor.py:186} INFO - Started process (PID=299) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:02:30.860+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:02:30.863+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:02:30.862+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:02:31.193+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:02:31.223+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:02:31.223+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:02:31.257+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:02:31.257+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:02:31.284+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.431 seconds
[2025-01-13T13:02:42.573+0000] {processor.py:186} INFO - Started process (PID=292) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:02:42.574+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:02:42.576+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:02:42.576+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:02:42.948+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:02:42.967+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:02:42.966+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:02:42.988+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:02:42.987+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:02:43.002+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.434 seconds
[2025-01-13T13:03:01.571+0000] {processor.py:186} INFO - Started process (PID=306) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:03:01.572+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:03:01.575+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:03:01.574+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:03:01.912+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:03:01.935+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:03:01.935+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:03:01.961+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:03:01.961+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:03:01.978+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.414 seconds
[2025-01-13T13:03:13.272+0000] {processor.py:186} INFO - Started process (PID=300) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:03:13.273+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:03:13.275+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:03:13.275+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:03:13.652+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:03:13.669+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:03:13.669+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:03:13.687+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:03:13.687+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:03:13.701+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.435 seconds
[2025-01-13T13:03:32.281+0000] {processor.py:186} INFO - Started process (PID=313) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:03:32.282+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:03:32.284+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:03:32.284+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:03:32.603+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:03:32.643+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:03:32.643+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:03:32.675+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:03:32.675+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:03:32.701+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.427 seconds
[2025-01-13T13:03:44.010+0000] {processor.py:186} INFO - Started process (PID=307) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:03:44.010+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:03:44.012+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:03:44.012+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:03:44.384+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:03:44.402+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:03:44.402+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:03:44.419+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:03:44.419+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:03:44.440+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.435 seconds
[2025-01-13T13:04:02.981+0000] {processor.py:186} INFO - Started process (PID=320) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:04:02.982+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:04:02.989+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:04:02.989+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:04:03.262+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:04:03.290+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:04:03.290+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:04:03.317+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:04:03.317+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:04:03.346+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.370 seconds
[2025-01-13T13:04:14.700+0000] {processor.py:186} INFO - Started process (PID=314) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:04:14.701+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:04:14.703+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:04:14.703+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:04:15.117+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:04:15.136+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:04:15.135+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:04:15.154+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:04:15.154+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:04:15.180+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.488 seconds
[2025-01-13T13:04:34.009+0000] {processor.py:186} INFO - Started process (PID=327) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:04:34.012+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:04:34.024+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:04:34.023+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:04:34.426+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:04:34.455+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:04:34.455+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:04:34.485+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:04:34.485+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:04:34.509+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.514 seconds
[2025-01-13T13:04:46.110+0000] {processor.py:186} INFO - Started process (PID=322) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:04:46.112+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:04:46.116+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:04:46.116+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:04:47.065+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:04:47.154+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:04:47.152+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:04:47.199+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:04:47.198+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:04:47.223+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 1.135 seconds
[2025-01-13T13:05:04.724+0000] {processor.py:186} INFO - Started process (PID=334) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:05:04.725+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:05:04.728+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:05:04.728+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:05:05.061+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:05:05.093+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:05:05.092+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:05:05.128+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:05:05.128+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:05:05.149+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.434 seconds
[2025-01-13T13:05:17.337+0000] {processor.py:186} INFO - Started process (PID=329) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:05:17.338+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:05:17.340+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:05:17.340+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:05:17.833+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:05:17.852+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:05:17.852+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:05:17.873+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:05:17.873+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:05:17.888+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.558 seconds
[2025-01-13T13:05:35.414+0000] {processor.py:186} INFO - Started process (PID=341) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:05:35.415+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:05:35.417+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:05:35.416+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:05:35.691+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:05:35.715+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:05:35.715+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:05:35.738+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:05:35.738+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:05:35.761+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.353 seconds
[2025-01-13T13:05:48.162+0000] {processor.py:186} INFO - Started process (PID=336) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:05:48.163+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:05:48.166+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:05:48.166+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:05:48.571+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:05:48.591+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:05:48.591+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:05:48.610+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:05:48.610+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:05:48.628+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.472 seconds
[2025-01-13T13:06:06.010+0000] {processor.py:186} INFO - Started process (PID=347) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:06:06.012+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:06:06.015+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:06:06.015+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:06:06.326+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:06:06.350+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:06:06.349+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:06:06.372+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:06:06.372+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:06:06.390+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.387 seconds
[2025-01-13T13:06:18.910+0000] {processor.py:186} INFO - Started process (PID=343) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:06:18.911+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:06:18.913+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:06:18.913+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:06:19.323+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:06:19.342+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:06:19.341+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:06:19.360+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:06:19.360+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:06:19.375+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.470 seconds
[2025-01-13T13:06:36.642+0000] {processor.py:186} INFO - Started process (PID=355) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:06:36.643+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:06:36.645+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:06:36.644+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:06:36.918+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:06:36.944+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:06:36.943+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:06:36.971+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:06:36.971+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:06:37.005+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.369 seconds
[2025-01-13T13:06:49.670+0000] {processor.py:186} INFO - Started process (PID=351) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:06:49.672+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:06:49.674+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:06:49.674+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:06:50.120+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:06:50.139+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:06:50.138+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:06:50.158+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:06:50.158+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:06:50.173+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.509 seconds
[2025-01-13T13:07:07.289+0000] {processor.py:186} INFO - Started process (PID=361) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:07:07.290+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:07:07.295+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:07:07.293+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:07:07.619+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:07:07.651+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:07:07.648+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:07:07.696+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:07:07.695+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:07:07.717+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.434 seconds
[2025-01-13T13:07:20.365+0000] {processor.py:186} INFO - Started process (PID=358) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:07:20.366+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:07:20.370+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:07:20.369+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:07:20.881+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:07:20.901+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:07:20.901+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:07:20.925+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:07:20.925+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:07:20.947+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.588 seconds
[2025-01-13T13:07:37.965+0000] {processor.py:186} INFO - Started process (PID=369) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:07:37.966+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:07:37.969+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:07:37.968+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:07:38.250+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:07:38.278+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:07:38.278+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:07:38.303+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:07:38.303+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:07:38.321+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.361 seconds
[2025-01-13T13:07:51.204+0000] {processor.py:186} INFO - Started process (PID=366) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:07:51.205+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:07:51.207+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:07:51.207+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:07:51.574+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:07:51.592+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:07:51.591+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:07:51.609+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:07:51.609+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:07:51.629+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.432 seconds
[2025-01-13T13:08:08.876+0000] {processor.py:186} INFO - Started process (PID=376) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:08:08.886+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:08:08.890+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:08:08.890+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:08:10.071+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:08:10.176+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:08:10.176+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:08:10.256+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:08:10.256+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:08:10.306+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 1.508 seconds
[2025-01-13T13:10:26.280+0000] {processor.py:186} INFO - Started process (PID=61) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:10:26.281+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:10:26.291+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:10:26.290+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:10:27.979+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:10:28.051+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:10:28.050+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:10:28.084+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:10:28.084+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:10:28.105+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 1.845 seconds
[2025-01-13T13:10:58.418+0000] {processor.py:186} INFO - Started process (PID=68) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:10:58.419+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:10:58.421+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:10:58.421+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:10:58.845+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:10:58.863+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:10:58.862+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:10:58.881+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:10:58.881+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:10:58.897+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.484 seconds
[2025-01-13T13:11:29.137+0000] {processor.py:186} INFO - Started process (PID=75) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:11:29.138+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:11:29.140+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:11:29.140+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:11:29.529+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:11:29.550+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:11:29.549+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:11:29.568+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:11:29.567+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:11:29.582+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.451 seconds
[2025-01-13T13:11:59.943+0000] {processor.py:186} INFO - Started process (PID=81) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:11:59.944+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:11:59.946+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:11:59.946+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:12:00.344+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:12:00.365+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:12:00.364+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:12:00.385+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:12:00.385+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:12:00.405+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.467 seconds
[2025-01-13T13:12:30.724+0000] {processor.py:186} INFO - Started process (PID=88) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:12:30.725+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:12:30.727+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:12:30.727+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:12:31.105+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:12:31.123+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:12:31.123+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:12:31.142+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:12:31.142+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:12:31.157+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.438 seconds
[2025-01-13T13:13:01.425+0000] {processor.py:186} INFO - Started process (PID=95) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:13:01.426+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:13:01.428+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:13:01.428+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:13:01.794+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:13:01.813+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:13:01.812+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:13:01.834+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:13:01.834+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:13:01.861+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.441 seconds
[2025-01-13T13:13:32.305+0000] {processor.py:186} INFO - Started process (PID=102) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:13:32.305+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:13:32.308+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:13:32.307+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:13:32.682+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:13:32.713+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:13:32.711+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:13:32.736+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:13:32.735+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:13:32.754+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.455 seconds
[2025-01-13T13:14:02.928+0000] {processor.py:186} INFO - Started process (PID=109) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:14:02.931+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:14:02.942+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:14:02.942+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:14:03.635+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:14:03.657+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:14:03.656+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:14:03.677+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:14:03.677+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:14:03.706+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.784 seconds
[2025-01-13T13:14:34.114+0000] {processor.py:186} INFO - Started process (PID=117) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:14:34.116+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:14:34.118+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:14:34.117+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:14:34.665+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:14:34.685+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:14:34.684+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:14:34.705+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:14:34.704+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:14:34.720+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.616 seconds
[2025-01-13T13:15:05.061+0000] {processor.py:186} INFO - Started process (PID=124) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:15:05.062+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:15:05.064+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:15:05.064+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:15:05.452+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:15:05.472+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:15:05.472+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:15:05.491+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:15:05.491+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:15:05.507+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.451 seconds
[2025-01-13T13:15:35.796+0000] {processor.py:186} INFO - Started process (PID=131) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:15:35.797+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:15:35.800+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:15:35.800+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:15:36.165+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:15:36.184+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:15:36.183+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:15:36.202+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:15:36.202+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:15:36.216+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.431 seconds
[2025-01-13T13:16:06.618+0000] {processor.py:186} INFO - Started process (PID=137) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:16:06.619+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:16:06.621+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:16:06.621+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:16:06.981+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:16:06.998+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:16:06.998+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:16:07.016+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:16:07.016+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:16:07.038+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.424 seconds
[2025-01-13T13:16:37.455+0000] {processor.py:186} INFO - Started process (PID=144) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:16:37.455+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:16:37.457+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:16:37.457+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:16:37.828+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:16:37.845+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:16:37.844+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:16:37.862+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:16:37.861+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:16:37.876+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.426 seconds
[2025-01-13T13:17:08.127+0000] {processor.py:186} INFO - Started process (PID=151) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:17:08.128+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:17:08.130+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:17:08.130+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:17:08.546+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:17:08.565+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:17:08.565+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:17:08.586+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:17:08.586+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:17:08.602+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.480 seconds
[2025-01-13T13:17:38.831+0000] {processor.py:186} INFO - Started process (PID=159) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:17:38.832+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:17:38.834+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:17:38.834+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:17:39.219+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:17:39.236+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:17:39.236+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:17:39.256+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:17:39.255+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:17:39.270+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.444 seconds
[2025-01-13T13:18:09.610+0000] {processor.py:186} INFO - Started process (PID=166) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:18:09.611+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:18:09.613+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:18:09.613+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:18:09.979+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:18:09.996+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:18:09.996+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:18:10.014+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:18:10.014+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:18:10.035+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.430 seconds
[2025-01-13T13:18:40.404+0000] {processor.py:186} INFO - Started process (PID=173) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:18:40.405+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:18:40.407+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:18:40.407+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:18:40.808+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:18:40.826+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:18:40.825+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:18:40.842+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:18:40.842+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:18:40.857+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.458 seconds
[2025-01-13T13:19:11.152+0000] {processor.py:186} INFO - Started process (PID=180) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:19:11.153+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:19:11.155+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:19:11.155+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:19:11.543+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:19:11.561+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:19:11.561+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:19:11.579+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:19:11.579+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:19:11.594+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.449 seconds
[2025-01-13T13:19:41.892+0000] {processor.py:186} INFO - Started process (PID=186) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:19:41.893+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:19:41.895+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:19:41.895+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:19:42.284+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:19:42.302+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:19:42.302+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:19:42.323+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:19:42.322+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:19:42.336+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.448 seconds
[2025-01-13T13:20:12.619+0000] {processor.py:186} INFO - Started process (PID=193) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:20:12.620+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:20:12.622+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:20:12.622+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:20:13.111+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:20:13.131+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:20:13.130+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:20:13.155+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:20:13.155+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:20:13.177+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.564 seconds
[2025-01-13T13:20:43.328+0000] {processor.py:186} INFO - Started process (PID=207) to work on /opt/airflow/dags/crawl_data.py
[2025-01-13T13:20:43.329+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/crawl_data.py for tasks to queue
[2025-01-13T13:20:43.331+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:20:43.331+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:20:43.724+0000] {processor.py:925} INFO - DAG(s) 'topcv_scraper' retrieved from /opt/airflow/dags/crawl_data.py
[2025-01-13T13:20:43.747+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:20:43.746+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-13T13:20:43.772+0000] {logging_mixin.py:190} INFO - [2025-01-13T13:20:43.771+0000] {dag.py:4180} INFO - Setting next_dagrun for topcv_scraper to 2025-01-13 00:00:00+00:00, run_after=2025-01-14 00:00:00+00:00
[2025-01-13T13:20:43.793+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/crawl_data.py took 0.471 seconds
